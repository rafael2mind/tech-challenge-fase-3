{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm",
      "mount_file_id": "1rmMsimThUdMOvd3vYzqdp7I0nTBP_Pr9",
      "authorship_tag": "ABX9TyMLMO1x9LPfrOKi5epDUz/U"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2bb4eb61f6474d4ab863dbd2f348064c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d77ebd0f5a54bd1a9b67970e844ecd0",
              "IPY_MODEL_591540dfd76a4319a396166854eb09d9",
              "IPY_MODEL_71e1ded379394184bd6ed62c04bb1fbd"
            ],
            "layout": "IPY_MODEL_4121b26b63644f1089b5225f174c67a5"
          }
        },
        "8d77ebd0f5a54bd1a9b67970e844ecd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17a94668ca9642d28a20e5ab6bb7df69",
            "placeholder": "​",
            "style": "IPY_MODEL_b8b836f25a7644fd96c20cdf1484a01d",
            "value": "Map: 100%"
          }
        },
        "591540dfd76a4319a396166854eb09d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c5ad1af5ef44e258f3f0f568e62aa89",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9b30223cb964a1e8e1f2bc2e785e373",
            "value": 10000
          }
        },
        "71e1ded379394184bd6ed62c04bb1fbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62dd7d3a93524c22b3006ab3e8db7e56",
            "placeholder": "​",
            "style": "IPY_MODEL_b9cda97674624be2bb1366f151e9f424",
            "value": " 10000/10000 [00:02&lt;00:00, 3497.06 examples/s]"
          }
        },
        "4121b26b63644f1089b5225f174c67a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17a94668ca9642d28a20e5ab6bb7df69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8b836f25a7644fd96c20cdf1484a01d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c5ad1af5ef44e258f3f0f568e62aa89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9b30223cb964a1e8e1f2bc2e785e373": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "62dd7d3a93524c22b3006ab3e8db7e56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9cda97674624be2bb1366f151e9f424": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Tech Challenge - FIAP: IA para Devs (Fase 3)\n",
        "\n",
        "###Grupo 38\n",
        "- Pedro Vianna Silveira\n",
        "- Rafael Silva Souza\n",
        "- Rodrigo de Freitas Ornellas\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### 🔗 Código Github\n",
        "\n",
        "\n",
        "\n",
        "https://github.com/rafael2mind/tech-challenge-fase-3\n",
        "\n",
        "\n",
        "### 🔗 Vídeo de apresentação\n",
        "https://youtu.be/\n",
        "\n",
        "---\n",
        "\n",
        "### 1. Introdução\n",
        "\n",
        "#### Contexto e Motivação\n",
        "\n",
        "Nesta fase do Tech Challenge, o foco está em realizar o fine-tuning de um foundation model (como BERT, Llama, Mistral, etc.) utilizando o dataset AmazonTitles-1.3MM. O objetivo é treinar o modelo para responder perguntas dos usuários com base nas descrições de produtos fornecidas no dataset.\n",
        "\n",
        "O dataset AmazonTitles-1.3MM contém consultas textuais reais de usuários sobre produtos da Amazon, associadas a títulos de produtos e suas respectivas descrições. Com o aumento das interações em plataformas de e-commerce, há uma crescente necessidade de sistemas que consigam entender perguntas dos usuários e gerar respostas relevantes, utilizando descrições detalhadas dos produtos.\n",
        "\n",
        "Este projeto propõe a construção de um sistema onde, a partir de uma pergunta do usuário sobre um título de produto, o modelo será capaz de gerar uma resposta adequada, utilizando o conhecimento adquirido no processo de fine-tuning com o dataset.\n",
        "\n",
        "\n",
        "#### Objetivos do Projeto\n",
        "\n",
        "O principal objetivo deste projeto é realizar o fine-tuning de um modelo de linguagem com o dataset AmazonTitles-1.3MM para permitir que o modelo:\n",
        "\n",
        "1. Gere respostas baseadas nas descrições dos produtos: A partir de uma pergunta feita pelo usuário sobre o título de um produto, o modelo deverá gerar uma resposta utilizando as descrições presentes no dataset.\n",
        "2. Melhore a precisão e relevância das respostas: O fine-tuning do modelo deve permitir uma compreensão mais profunda das relações entre o título e a descrição de um produto, resultando em respostas mais informativas e úteis para o usuário.\n",
        "3. Documente o processo de ajuste fino: Descrever detalhadamente as etapas de pré-processamento de dados, ajuste de hiperparâmetros e qualquer modificação feita ao modelo durante o treinamento.\n",
        "\n",
        "\n",
        "#### Estrutura do Projeto\n",
        "\n",
        "O projeto será desenvolvido em várias etapas, conforme detalhado a seguir:\n",
        "\n",
        "1. **Introdução**:\n",
        "   - Contextualização do problema.\n",
        "   - Objetivos do projeto: foco no fine-tuning de um foundation model (como BERT, Llama, Mistral) utilizando o dataset AmazonTitles-1.3MM para gerar respostas baseadas em descrições de produtos.\n",
        "\n",
        "2. **Descrição do Problema**:\n",
        "   - Definição do problema: necessidade de sistemas de NLP capazes de gerar respostas baseadas nas descrições de produtos.\n",
        "   - Importância do problema no contexto de plataformas de e-commerce.\n",
        "   - Abordagem para a resolução do problema.\n",
        "\n",
        "3. **Fundamentação Teórica**:\n",
        "   - Modelos de linguagem (foundation models) como BERT, Llama, Mistral.\n",
        "   - Fine-tuning: técnica de ajuste fino do modelo para tarefas específicas.\n",
        "   - Pré-processamento de dados textuais: tokenização, normalização, remoção de stop words.\n",
        "   - Geração de respostas em NLP.\n",
        "\n",
        "4. **Metodologia**:\n",
        "   - **Preparação dos Dados**: Carregamento do dataset AmazonTitles-1.3MM e pré-processamento, incluindo limpeza e criação de prompts.\n",
        "   - **Seleção e Configuração do Modelo**: Escolha de um modelo adequado (BERT, Llama, etc.) e tokenização dos dados.\n",
        "   - **Execução do Fine-Tuning**: Configuração de hiperparâmetros, treinamento do modelo e ajustes ao longo do processo.\n",
        "   - **Avaliação e Validação**: Teste do modelo treinado e comparação com o modelo pré-treinado.\n",
        "\n",
        "5. **Implementação**:\n",
        "   - Descrição do ambiente de desenvolvimento: ferramentas como Google Colab, bibliotecas como Transformers, Pandas, NumPy, Matplotlib, TensorFlow ou PyTorch.\n",
        "   - **Carregamento e Preparação do Dataset**: Código de carregamento, limpeza e tokenização dos dados.\n",
        "   - **Fine-tuning do Modelo Escolhido**: Execução do ajuste fino e salvamento do modelo treinado.\n",
        "   - **Geração de Respostas e Testes**: Função para gerar respostas a partir de perguntas, avaliação de métricas como acurácia e F1-score.\n",
        "\n",
        "6. **Resultados**:\n",
        "   - Análise comparativa do modelo pré-treinado e fine-tunado.\n",
        "   - Métricas de avaliação e discussão dos resultados obtidos.\n",
        "   - Análise qualitativa das respostas geradas pelo modelo.\n",
        "\n",
        "7. **Conclusão**:\n",
        "   - Revisão dos objetivos e resultados.\n",
        "   - Limitações do projeto e sugestões de melhorias para trabalhos futuros.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "VUGPK79JEHwp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Descrição do Problema\n",
        "\n",
        "#### Definição do Problema\n",
        "\n",
        "Neste Tech Challenge, o problema central é realizar o **fine-tuning** de um **foundation model** (como Llama, BERT, ou Mistral) utilizando o dataset **AmazonTitles-1.3MM**, que contém perguntas feitas por usuários sobre produtos da Amazon e suas respectivas descrições. O objetivo é treinar o modelo para gerar respostas relevantes a partir dessas descrições, com base em perguntas relacionadas aos títulos dos produtos.\n",
        "\n",
        "A tarefa proposta envolve construir um sistema que possa compreender o contexto de uma pergunta do usuário, buscar informações adequadas nas descrições dos produtos e retornar uma resposta que seja ao mesmo tempo precisa e informativa. Isso exige um fine-tuning cuidadoso do modelo para adaptar seu conhecimento às características específicas do dataset.\n",
        "\n",
        "#### Importância\n",
        "\n",
        "O desenvolvimento de modelos de linguagem que consigam responder de maneira precisa e contextualizada é essencial para plataformas de e-commerce, como a Amazon, onde a interação dos usuários com o sistema muitas vezes depende de respostas rápidas e relevantes. Ao utilizar descrições detalhadas dos produtos, o modelo pode melhorar significativamente a experiência do usuário ao fornecer informações que auxiliam nas decisões de compra.\n",
        "\n",
        "Além disso, este tipo de sistema pode ser escalado para várias outras plataformas, onde a compreensão do contexto e a geração de respostas personalizadas são críticas para o sucesso de uma interação automatizada.\n",
        "\n",
        "#### Objetivos e Critérios de Sucesso\n",
        "\n",
        "Os principais objetivos deste desafio incluem:\n",
        "- **Treinar um modelo de linguagem** capaz de responder a perguntas de usuários com base nas descrições de produtos.\n",
        "- **Melhorar a precisão e a relevância das respostas** fornecidas pelo modelo após o fine-tuning.\n",
        "- **Documentar o processo de treinamento e ajustes** do modelo, garantindo a replicabilidade.\n",
        "\n",
        "Critérios de sucesso:\n",
        "- **Acurácia nas respostas**: O modelo deverá ser capaz de gerar respostas precisas e informativas, com base no contexto dado pela pergunta e nas descrições dos produtos.\n",
        "- **Eficiência do treinamento**: O modelo deverá ser treinado com parâmetros otimizados para garantir um tempo de resposta rápido e uma geração de respostas de alta qualidade.\n",
        "- **Escalabilidade**: O sistema deve ser capaz de lidar com um grande volume de perguntas e descrições, mantendo a eficiência e qualidade.\n",
        "\n",
        "#### Abordagem para a Resolução do Problema\n",
        "\n",
        "A abordagem para resolver o problema envolve as seguintes etapas:\n",
        "1. **Preparação dos Dados**: Extrair e pré-processar os dados relevantes do dataset **AmazonTitles-1.3MM** (colunas de título e descrição), garantindo que estejam em um formato adequado para o fine-tuning do modelo.\n",
        "2. **Seleção do Modelo**: Escolher um **foundation model** que seja adequado para a tarefa de geração de respostas com base em descrições de produtos.\n",
        "3. **Fine-Tuning**: Ajustar o modelo utilizando o dataset preparado, otimizando os hiperparâmetros para garantir a melhor performance possível.\n",
        "4. **Testes e Avaliação**: Testar o modelo treinado com um conjunto de perguntas para verificar a qualidade e precisão das respostas geradas. A performance será comparada com o estado inicial do modelo antes do fine-tuning.\n",
        "5. **Análise dos Resultados**: Avaliar os resultados obtidos e verificar se os critérios de sucesso foram atingidos, documentando possíveis melhorias e ajustes para o futuro.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "2obifMY3HMWZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Fundamentação Teórica\n",
        "\n",
        "Nesta seção, serão apresentados os principais conceitos teóricos que embasam a execução do projeto, com foco em modelos de linguagem, fine-tuning, e pré-processamento de dados textuais.\n",
        "\n",
        "#### 3.1 Modelos de Linguagem (Foundation Models)\n",
        "\n",
        "**Modelos de linguagem**, como **BERT (Bidirectional Encoder Representations from Transformers)** e **Llama**, são algoritmos projetados para processar e compreender a linguagem natural. Esses modelos são baseados em arquiteturas de redes neurais profundas, em particular os **Transformers**, que utilizam mecanismos de atenção para capturar a relação entre palavras e frases em um texto. A principal vantagem dos Transformers em relação a outros modelos mais antigos, como as redes recorrentes (RNNs), é a sua capacidade de processar grandes quantidades de dados em paralelo, preservando o contexto das palavras independentemente da posição em que elas aparecem no texto.\n",
        "\n",
        "Esses modelos são chamados de **foundation models** porque servem como ponto de partida para várias tarefas de **NLP (Natural Language Processing)**, como geração de texto, tradução, sumarização e resposta a perguntas. No contexto deste projeto, o fine-tuning de um modelo de linguagem permitirá que ele gere respostas baseadas em descrições de produtos, ajustando seu conhecimento prévio para uma tarefa específica.\n",
        "\n",
        "#### 3.2 Fine-Tuning\n",
        "\n",
        "O processo de **fine-tuning** é uma técnica de transferência de aprendizado. Ele envolve o ajuste fino de um modelo pré-treinado em um grande corpus de dados (como BERT ou Llama) para uma tarefa mais específica, utilizando um conjunto de dados especializado. Em vez de treinar um modelo do zero, o fine-tuning aproveita o conhecimento que o modelo já adquiriu durante seu treinamento original e o adapta para resolver um problema específico.\n",
        "\n",
        "No caso deste trabalho, o fine-tuning será realizado no **foundation model** utilizando o dataset **AmazonTitles-1.3MM**, composto por títulos e descrições de produtos. Isso permitirá que o modelo aprenda a responder perguntas dos usuários sobre os produtos, com base nas descrições detalhadas.\n",
        "\n",
        "#### 3.3 Pré-Processamento de Dados Textuais\n",
        "\n",
        "O **pré-processamento de dados textuais** é uma etapa crucial para o sucesso de qualquer modelo de NLP. Esse processo inclui várias técnicas que garantem que os dados estejam limpos e em um formato adequado para serem utilizados no treinamento do modelo. As principais técnicas de pré-processamento incluem:\n",
        "\n",
        "- **Tokenização**: Dividir o texto em unidades menores, como palavras ou subpalavras, que serão utilizadas como input para o modelo.\n",
        "- **Normalização**: Convertendo todos os caracteres para minúsculas, removendo pontuações e aplicando stemming ou lematização para reduzir palavras à sua forma básica.\n",
        "- **Remoção de Stop Words**: Stop words são palavras comuns, como artigos e preposições, que muitas vezes são removidas para reduzir a complexidade do texto sem perder o significado.\n",
        "\n",
        "Essas etapas são fundamentais para garantir que o dataset **AmazonTitles-1.3MM** esteja em um formato otimizado para o fine-tuning do modelo.\n",
        "\n",
        "#### 3.4 Geração de Respostas em NLP\n",
        "\n",
        "A **geração de respostas** em sistemas de NLP refere-se à capacidade de um modelo de linguagem gerar uma resposta coerente e relevante a partir de uma entrada fornecida pelo usuário. Este tipo de tarefa é amplamente utilizado em sistemas de atendimento ao cliente, chatbots e assistentes virtuais. No caso deste projeto, o objetivo é treinar o modelo para que, a partir de uma pergunta sobre o título de um produto, ele seja capaz de gerar uma resposta baseada na descrição contida no dataset.\n",
        "\n",
        "Modelos que realizam **geração de respostas** utilizam tanto técnicas de aprendizado supervisionado quanto aprendizado não supervisionado, com o intuito de generalizar e inferir respostas que sejam adequadas ao contexto fornecido.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "JX5DslD6HvD-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Metodologia\n",
        "\n",
        "Nesta seção, será detalhada a metodologia adotada para a implementação do projeto. A abordagem segue uma sequência estruturada, desde a preparação dos dados até o fine-tuning do modelo, passando pelos processos de avaliação e testes.\n",
        "\n",
        "#### 4.1 Preparação dos Dados\n",
        "\n",
        "A primeira etapa do projeto será a **preparação do dataset** **AmazonTitles-1.3MM**. Esse processo envolverá:\n",
        "\n",
        "- **Carregamento do Dataset**: O arquivo **\"trn.json\"** será lido e explorado, focando nas colunas relevantes para o fine-tuning: **\"title\"** (título do produto) e **\"content\"** (descrição do produto).\n",
        "- **Limpeza e Normalização dos Dados**: Será realizada a remoção de inconsistências e duplicatas nos dados. Os textos das descrições passarão por um processo de normalização, que inclui a remoção de caracteres especiais, tokenização, e a padronização de caixa (minúsculas).\n",
        "- **Criação de Prompts**: Para treinar o modelo, serão criados prompts que combinem perguntas baseadas nos títulos dos produtos com as descrições correspondentes. Esses prompts servirão como entradas para o modelo durante o fine-tuning.\n",
        "\n",
        "#### 4.2 Seleção e Configuração do Modelo\n",
        "\n",
        "A segunda etapa consiste na **seleção do foundation model** a ser utilizado para o fine-tuning. Entre as opções estão modelos populares como **BERT**, **Llama** ou **Mistral**, todos baseados em arquiteturas de transformers e conhecidos por seu desempenho em tarefas de NLP. A escolha será baseada na capacidade do modelo de lidar com grandes volumes de dados textuais e sua eficiência no processo de fine-tuning.\n",
        "\n",
        "- **Pré-treino**: O modelo escolhido será avaliado antes do fine-tuning, utilizando uma parte do dataset para verificar sua performance inicial, estabelecendo uma base de comparação.\n",
        "- **Configuração de Hiperparâmetros**: Serão definidos os principais hiperparâmetros, como taxa de aprendizado, número de épocas, tamanho do lote, e otimizações específicas para o modelo, visando maximizar o desempenho durante o treinamento.\n",
        "\n",
        "#### 4.3 Execução do Fine-Tuning\n",
        "\n",
        "Após a preparação dos dados e a configuração do modelo, será realizada a etapa de **fine-tuning**. Esse processo envolverá:\n",
        "\n",
        "- **Alimentar o Modelo com os Prompts Criados**: O modelo será treinado com os prompts que combinam perguntas sobre os títulos dos produtos com as respostas esperadas, que são as descrições correspondentes.\n",
        "- **Ajuste Fino dos Hiperparâmetros**: Durante o treinamento, os hiperparâmetros serão ajustados conforme necessário para garantir a melhor performance possível. Isso inclui ajustes na taxa de aprendizado e no número de épocas, com base nas avaliações realizadas após cada ciclo de treinamento.\n",
        "- **Documentação do Processo**: Cada etapa do fine-tuning será documentada, incluindo os parâmetros utilizados, os ajustes realizados, e os resultados intermediários obtidos após cada ciclo de treinamento.\n",
        "\n",
        "#### 4.4 Avaliação e Validação\n",
        "\n",
        "A etapa de **avaliação** será crítica para verificar a eficiência do fine-tuning. O modelo será testado com um conjunto de perguntas relacionadas aos títulos dos produtos, e as respostas geradas serão comparadas com as descrições esperadas.\n",
        "\n",
        "- **Métricas de Avaliação**: Serão utilizadas métricas como **acurácia**, **precisão**, **recall**, e **F1-score** para medir a qualidade das respostas geradas pelo modelo. Esses indicadores ajudarão a verificar se o modelo foi capaz de aprender adequadamente com o dataset e se consegue gerar respostas relevantes.\n",
        "- **Comparação Antes e Depois do Fine-Tuning**: Os resultados obtidos após o fine-tuning serão comparados com a performance inicial do modelo, para quantificar a melhora na precisão das respostas.\n",
        "\n",
        "#### 4.5 Iteração e Refinamento\n",
        "\n",
        "Dependendo dos resultados da avaliação, poderá ser necessário realizar iterações no processo de fine-tuning. Isso inclui:\n",
        "\n",
        "- **Reajuste de Hiperparâmetros**: Caso a performance do modelo não seja satisfatória, novos ajustes de hiperparâmetros poderão ser feitos para otimizar os resultados.\n",
        "- **Refinamento dos Dados de Entrada**: Se o modelo apresentar dificuldades com certas perguntas ou tipos de descrições, pode ser necessário refinar a forma como os dados são apresentados ao modelo, ajustando os prompts ou a estrutura do dataset.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "R6yHlhiUIVeR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Implementação\n",
        "\n",
        "### 5.1 Descrição do Ambiente de Desenvolvimento (Ferramentas e Bibliotecas Utilizadas)\n",
        "\n",
        "Para a implementação do projeto, será utilizado um ambiente de desenvolvimento composto por ferramentas e bibliotecas que facilitam o pré-processamento dos dados, o treinamento do modelo e a avaliação de resultados. Abaixo, segue uma descrição das principais tecnologias utilizadas:\n",
        "\n",
        "#### 5.1.1 Ferramentas\n",
        "\n",
        "- **Google Colab**: Utilizado como ambiente principal de desenvolvimento. O Google Colab fornece uma infraestrutura baseada em nuvem, com suporte para execução de código Python, permitindo acesso a GPUs e TPUs para acelerar o processo de treinamento de modelos de deep learning.\n",
        "- **Python**: Linguagem de programação principal utilizada no projeto, pela sua ampla adoção na área de aprendizado de máquina e NLP (Natural Language Processing).\n",
        "- **GitHub**: Usado para o controle de versão e colaboração entre os membros do grupo. Todo o código será versionado e armazenado em um repositório público ou privado no GitHub.\n",
        "\n",
        "#### 5.1.2 Bibliotecas\n",
        "\n",
        "- **Transformers** (da Hugging Face): Biblioteca utilizada para o carregamento e fine-tuning de modelos de linguagem como **BERT**, **Llama**, ou **Mistral**. Ela fornece uma interface fácil para trabalhar com os principais modelos pré-treinados e realizar ajustes finos.\n",
        "- **Pandas**: Usado para a manipulação e análise dos dados do dataset **AmazonTitles-1.3MM**, permitindo a leitura e preparação das colunas de título e descrição do produto.\n",
        "- **NumPy**: Biblioteca fundamental para operações matemáticas e manipulação de arrays, utilizada em conjunto com o Pandas para processamento de dados.\n",
        "- **Scikit-learn**: Utilizada para calcular métricas de avaliação como acurácia, precisão, recall e F1-score, além de fornecer ferramentas para dividir o dataset em conjuntos de treinamento e teste.\n",
        "\n",
        "#### 5.1.3 Infraestrutura\n",
        "\n",
        "- **GPU/TPU**: O uso de uma GPU ou TPU no Google Colab será crucial para acelerar o treinamento do modelo durante o fine-tuning, dado o grande volume de dados do dataset **AmazonTitles-1.3MM**.\n",
        "- **Armazenamento em Nuvem**: O Google Drive será utilizado para armazenar datasets e checkpoints dos modelos, garantindo que todo o progresso do treinamento seja salvo de forma segura e acessível para futuras análises.\n"
      ],
      "metadata": {
        "id": "c5k7U0AXKMyD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5.2 Código de Carregamento e Preparação do Dataset\n",
        "\n",
        "Nesta etapa, será realizada a leitura do dataset AmazonTitles-1.3MM e o seu pré-processamento, com o objetivo de estruturar os dados para o fine-tuning do modelo. O foco estará nas colunas de “title” (título do produto) e “content” (descrição do produto), que serão usadas para construir os prompts que alimentarão o modelo.\n",
        "\n",
        "####5.2.1 Carregamento do Dataset"
      ],
      "metadata": {
        "id": "OjajeKZfLGq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Definindo o número máximo de linhas a serem carregadas\n",
        "max_rows = 10000\n",
        "dataset_path = '/content/drive/MyDrive/Pos tech/fase 3/LF-Amazon-1.3M/trn.json'\n",
        "\n",
        "# Carregando o dataset em pedaços e selecionando as primeiras 100 mil linhas\n",
        "df_chunks = pd.read_json(dataset_path, lines=True, chunksize=10000)\n",
        "df_limited = pd.concat([chunk for chunk in df_chunks][:max_rows // 10000], ignore_index=True)\n",
        "\n",
        "# Selecionando as colunas \"title\" e \"content\" (título e descrição do produto)\n",
        "df_limited = df_limited[['title', 'content']]\n",
        "\n",
        "# Remover valores nulos\n",
        "df_limited.dropna(subset=['title', 'content'], inplace=True)\n",
        "\n",
        "# Limpeza básica: remover espaços em branco e converter para minúsculas\n",
        "df_limited['title'] = df_limited['title'].str.strip().str.lower()\n",
        "df_limited['content'] = df_limited['content'].str.strip().str.lower()\n",
        "\n",
        "# Visualizando o dataset após a limpeza\n",
        "print(df_limited.head())"
      ],
      "metadata": {
        "id": "viM54RRgLkZM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94894590-acb8-4059-c28c-f72c5fee3b58"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               title  \\\n",
            "0                        girls ballet tutu neon pink   \n",
            "1                           adult ballet tutu yellow   \n",
            "2  the way things work: an illustrated encycloped...   \n",
            "3                                      mog's kittens   \n",
            "4                              misty of chincoteague   \n",
            "\n",
            "                                             content  \n",
            "0  high quality 3 layer ballet tutu. 12 inches in...  \n",
            "1                                                     \n",
            "2                                                     \n",
            "3  judith kerr&#8217;s best&#8211;selling adventu...  \n",
            "4                                                     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código carrega o dataset AmazonTitles-1.3MM diretamente de um arquivo JSON e o converte em um DataFrame do Pandas para facilitar a manipulação dos dados. A função head() permite visualizar as primeiras linhas do dataset, garantindo que os dados foram carregados corretamente. Aqui a gente seleciona as colunas necessárias, remove linhas com valores nulos e realiza uma limpeza básica nos textos, removendo espaços extras e convertendo os textos para letras minúsculas, o que ajuda a uniformizar os dados para o treinamento."
      ],
      "metadata": {
        "id": "BkRzrOUPOIp_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####5.2.3 Criação de Prompts para o Fine-Tuning\n",
        "\n",
        "O próximo passo é criar os prompts que serão usados no fine-tuning do modelo. Cada prompt será formado por uma pergunta relacionada ao título do produto, com a resposta sendo a descrição do produto."
      ],
      "metadata": {
        "id": "DS_m3pyyOsh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando prompts de perguntas e respostas para o fine-tuning no DataFrame limitado\n",
        "df_limited['prompt'] = 'Qual é a descrição deste produto: ' + df_limited['title'] + '?'\n",
        "df_limited['response'] = df_limited['content']\n",
        "\n",
        "# Visualizando as colunas de prompt e resposta\n",
        "print(df_limited[['prompt', 'response']].head())"
      ],
      "metadata": {
        "id": "aJl8PhnUOzNv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d05dbfd9-aaf0-4096-c59f-55ff9decbdcb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              prompt  \\\n",
            "0  Qual é a descrição deste produto: girls ballet...   \n",
            "1  Qual é a descrição deste produto: adult ballet...   \n",
            "2  Qual é a descrição deste produto: the way thin...   \n",
            "3   Qual é a descrição deste produto: mog's kittens?   \n",
            "4  Qual é a descrição deste produto: misty of chi...   \n",
            "\n",
            "                                            response  \n",
            "0  high quality 3 layer ballet tutu. 12 inches in...  \n",
            "1                                                     \n",
            "2                                                     \n",
            "3  judith kerr&#8217;s best&#8211;selling adventu...  \n",
            "4                                                     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código cria a coluna prompt, onde cada linha contém uma pergunta sobre o título do produto, e a coluna response, que contém a descrição do produto, que será a resposta esperada do modelo.\n",
        "\n",
        "####5.2.4 Salvando os Dados Preparados\n",
        "\n",
        "Após a preparação, os dados prontos para o treinamento podem ser salvos em um arquivo CSV ou em outro formato conveniente para uso posterior."
      ],
      "metadata": {
        "id": "hJvHVRhWO62w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvando o dataset preparado em um arquivo CSV\n",
        "df_limited.to_csv('dataset_preparado.csv', index=False)\n",
        "\n",
        "# Opção do JSON\n",
        "df_limited.to_json('dataset_preparado.json', orient='records', lines=True)"
      ],
      "metadata": {
        "id": "2wBV-YFlPBjV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esse trecho salva o dataset preparado em um arquivo CSV ou JSON, que será utilizado no treinamento do modelo de linguagem.\n"
      ],
      "metadata": {
        "id": "DVcGr12mPFP7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "###5.3 Fine-tuning do Modelo Escolhido\n",
        "\n",
        "Nesta etapa, o foco será realizar o fine-tuning do foundation model selecionado (por exemplo, BERT, Llama, ou Mistral) utilizando os dados previamente preparados. O fine-tuning consiste em ajustar os pesos do modelo para adaptar seu conhecimento geral ao problema específico, que neste caso é gerar respostas relacionadas a produtos da Amazon.\n",
        "\n",
        "####5.3.1 Importando o Modelo Pré-treinado\n",
        "\n",
        "A primeira etapa do fine-tuning é carregar o modelo pré-treinado da biblioteca Transformers da Hugging Face, e configurá-lo para ser ajustado com os prompts que foram criados no pré-processamento dos dados."
      ],
      "metadata": {
        "id": "BHKtHEpALKKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "login('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')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJVg3OJSq_h5",
        "outputId": "e0997d52-95ff-468d-e284-85c9430184aa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Verificando se o modelo e o tokenizer foram carregados corretamente\n",
        "print(\"Modelo e tokenizer GPT-2 carregados com sucesso.\")"
      ],
      "metadata": {
        "id": "VjgZAXBtLlBl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "261d5129-9a0e-4ee1-c2ab-f669c68d2ac3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo e tokenizer GPT-2 carregados com sucesso.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esse código carrega o tokenizer (responsável por converter o texto em tokens) e o modelo pré-treinado que será ajustado para a tarefa específica.\n",
        "\n",
        "####5.3.2 Tokenização dos Dados\n",
        "\n",
        "Os prompts e respostas precisam ser convertidos em tokens para que o modelo possa processá-los durante o treinamento. Abaixo está o código que realiza essa conversão utilizando o tokenizer."
      ],
      "metadata": {
        "id": "BylJ0umXPhgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y datasets pyarrow\n",
        "!pip install datasets pyarrow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 895
        },
        "id": "ZZnyA04bsJGH",
        "outputId": "df7098b4-19e4-407a-d00e-74ad60da0c39"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: datasets 3.0.1\n",
            "Uninstalling datasets-3.0.1:\n",
            "  Successfully uninstalled datasets-3.0.1\n",
            "Found existing installation: pyarrow 17.0.0\n",
            "Uninstalling pyarrow-17.0.0:\n",
            "  Successfully uninstalled pyarrow-17.0.0\n",
            "Collecting datasets\n",
            "  Using cached datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting pyarrow\n",
            "  Using cached pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.6)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.12.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Using cached datasets-3.0.1-py3-none-any.whl (471 kB)\n",
            "Using cached pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "Installing collected packages: pyarrow, datasets\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.6.1 requires pyarrow<16.2.0a0,>=16.1.0, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.0.1 pyarrow-17.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "datasets",
                  "pyarrow"
                ]
              },
              "id": "792521cb5d194e8cad3e489aa31c5e99"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "# Definindo o token de padding para o tokenizer\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Convertendo o DataFrame para um Dataset do Hugging Face\n",
        "dataset = Dataset.from_pandas(df_limited)\n",
        "\n",
        "# Função para tokenizar os prompts e respostas\n",
        "def tokenize_data(examples):\n",
        "    inputs = tokenizer(examples['prompt'], max_length=256, truncation=True, padding='max_length')\n",
        "    targets = tokenizer(examples['response'], max_length=256, truncation=True, padding='max_length')\n",
        "    return {'input_ids': inputs['input_ids'], 'attention_mask': inputs['attention_mask'], 'labels': targets['input_ids']}\n",
        "\n",
        "# Aplicando a tokenização no dataset\n",
        "tokenized_dataset = dataset.map(tokenize_data, batched=True)\n",
        "\n",
        "# Visualizando as primeiras entradas do dataset tokenizado\n",
        "print(tokenized_dataset[0])"
      ],
      "metadata": {
        "id": "GezQW3aaPrPO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "2bb4eb61f6474d4ab863dbd2f348064c",
            "8d77ebd0f5a54bd1a9b67970e844ecd0",
            "591540dfd76a4319a396166854eb09d9",
            "71e1ded379394184bd6ed62c04bb1fbd",
            "4121b26b63644f1089b5225f174c67a5",
            "17a94668ca9642d28a20e5ab6bb7df69",
            "b8b836f25a7644fd96c20cdf1484a01d",
            "4c5ad1af5ef44e258f3f0f568e62aa89",
            "c9b30223cb964a1e8e1f2bc2e785e373",
            "62dd7d3a93524c22b3006ab3e8db7e56",
            "b9cda97674624be2bb1366f151e9f424"
          ]
        },
        "outputId": "94f6c358-2910-4ca6-cf71-1b2a2083a929"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2bb4eb61f6474d4ab863dbd2f348064c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'title': 'girls ballet tutu neon pink', 'content': 'high quality 3 layer ballet tutu. 12 inches in length', 'prompt': 'Qual é a descrição deste produto: girls ballet tutu neon pink?', 'response': 'high quality 3 layer ballet tutu. 12 inches in length', 'input_ids': [46181, 38251, 257, 1715, 380, 16175, 28749, 2244, 68, 40426, 9390, 25, 4813, 47735, 9732, 84, 25988, 11398, 30, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [8929, 3081, 513, 7679, 47735, 9732, 84, 13, 1105, 8331, 287, 4129, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Carregando o modelo GPT-2 pré-treinado e o tokenizer\n",
        "model_name = 'gpt2'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "# Ajustando o pad_token_id para evitar os avisos\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Função para testar o modelo pré-treinado com algumas amostras do dataset\n",
        "def test_pretrained_model(examples, num_samples=5):\n",
        "    print(\"Resultados do modelo GPT-2 pré-treinado:\")\n",
        "\n",
        "    # Selecionando algumas amostras do dataset\n",
        "    samples = examples.select(range(num_samples))\n",
        "\n",
        "    for i, example in enumerate(samples):\n",
        "        # Gerando a entrada para o modelo\n",
        "        input_text = example['prompt']\n",
        "        inputs = tokenizer.encode(input_text, return_tensors='pt', padding=True, truncation=True)\n",
        "\n",
        "        # Gerando a saída do modelo\n",
        "        outputs = model.generate(inputs, max_length=100, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n",
        "        output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        print(f\"\\nAmostra {i+1}:\")\n",
        "        print(f\"Entrada: {input_text}\")\n",
        "        print(f\"Saída do modelo pré-treinado: {output_text}\")\n",
        "\n",
        "# Amostras\n",
        "samples_to_test = tokenized_dataset.select(range(5))\n",
        "\n",
        "# Realizando o teste com o modelo pré-treinado\n",
        "test_pretrained_model(samples_to_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXu11cF9Yu5j",
        "outputId": "55a5d025-ad98-4be6-9643-7ef6e88d2ac1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados do modelo GPT-2 pré-treinado:\n",
            "\n",
            "Amostra 1:\n",
            "Entrada: Qual é a descrição deste produto: girls ballet tutu neon pink?\n",
            "Saída do modelo pré-treinado: Qual é a descrição deste produto: girls ballet tutu neon pink?\n",
            "\n",
            "A: I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don\n",
            "\n",
            "Amostra 2:\n",
            "Entrada: Qual é a descrição deste produto: adult ballet tutu yellow?\n",
            "Saída do modelo pré-treinado: Qual é a descrição deste produto: adult ballet tutu yellow?\n",
            "\n",
            "A: Yes, it is.\n",
            "\n",
            "B: Yes, it is.\n",
            "\n",
            "C: Yes, it is.\n",
            "\n",
            "D: Yes, it is.\n",
            "\n",
            "E: Yes, it is.\n",
            "\n",
            "F: Yes, it is.\n",
            "\n",
            "G: Yes, it is.\n",
            "\n",
            "H: Yes, it is.\n",
            "\n",
            "I: Yes, it is.\n",
            "\n",
            "\n",
            "Amostra 3:\n",
            "Entrada: Qual é a descrição deste produto: the way things work: an illustrated encyclopedia of technology?\n",
            "Saída do modelo pré-treinado: Qual é a descrição deste produto: the way things work: an illustrated encyclopedia of technology?\n",
            "\n",
            "A: I think that the way things work is that we have to be able to understand the world around us. We have to be able to understand the world around us. We have to be able to understand the world around us. We have to be able to understand the world around us. We have to be able to understand the world around us. We have to be\n",
            "\n",
            "Amostra 4:\n",
            "Entrada: Qual é a descrição deste produto: mog's kittens?\n",
            "Saída do modelo pré-treinado: Qual é a descrição deste produto: mog's kittens?\n",
            "\n",
            "Miguel: I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't\n",
            "\n",
            "Amostra 5:\n",
            "Entrada: Qual é a descrição deste produto: misty of chincoteague?\n",
            "Saída do modelo pré-treinado: Qual é a descrição deste produto: misty of chincoteague?\n",
            "\n",
            "A: I don't know. I don't know.\n",
            "\n",
            "Q: What is the difference between a \"chincoteague\" and a \"chimé\" (chimé)?\n",
            "\n",
            "A: The difference is that the chincoteague is a very small amount of sugar, whereas the chimé is a very large amount of sugar.\n",
            "\n",
            "Q:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizamos os testes do modelo pré treinado, de forma que foi possível perceber a incapacidade do modelo de gerar respostas adequadas sem o fine-tuning.\n",
        "\n",
        "####5.3.3 Configuração dos Argumentos de Treinamento\n",
        "\n",
        "A próxima etapa é definir os parâmetros do treinamento, como número de épocas, taxa de aprendizado, e o uso de GPUs. Esses parâmetros determinam a forma como o modelo será ajustado."
      ],
      "metadata": {
        "id": "dA6L06v7PwOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "# Ajustando os parâmetros do treinamento\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    fp16=True,\n",
        "    gradient_accumulation_steps=8,\n",
        "    logging_steps=50,\n",
        "    save_steps=200,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        ")"
      ],
      "metadata": {
        "id": "CARKq1UwP25E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65be5cb1-c981-4d0d-e709-0daacc64c283"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código configura os principais parâmetros de treinamento, como o número de épocas e o tamanho do lote, além de definir a frequência de salvamento de checkpoints e de avaliação do modelo.\n",
        "\n",
        "####5.3.4 Treinamento do Modelo\n",
        "\n",
        "Com os dados tokenizados e os parâmetros configurados, o modelo está pronto para ser treinado. Abaixo está o código para executar o processo de fine-tuning utilizando a classe Trainer."
      ],
      "metadata": {
        "id": "Qt9fByf5P7_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividindo o dataset em 90% para treino e 10% para validação\n",
        "train_test_split = tokenized_dataset.train_test_split(test_size=0.1)\n",
        "train_dataset = train_test_split['train']\n",
        "eval_dataset = train_test_split['test']\n",
        "\n",
        "# Importando o Trainer\n",
        "from transformers import Trainer\n",
        "\n",
        "# Criando o Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        ")\n",
        "\n",
        "# Iniciando o treinamento\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "dfkTwUwzQA-N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "d4dad069-ff74-45fe-ea93-0f5bef726787"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='420' max='420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [420/420 08:12, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>4.411900</td>\n",
              "      <td>4.352449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>4.292800</td>\n",
              "      <td>4.331074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>4.258600</td>\n",
              "      <td>4.334816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>4.290800</td>\n",
              "      <td>4.328104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>4.239900</td>\n",
              "      <td>4.330693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>4.261700</td>\n",
              "      <td>4.332803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>4.207700</td>\n",
              "      <td>4.332448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>4.164600</td>\n",
              "      <td>4.343865</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=420, training_loss=4.265638823736282, metrics={'train_runtime': 493.4157, 'train_samples_per_second': 54.721, 'train_steps_per_second': 0.851, 'total_flos': 3511764910080000.0, 'train_loss': 4.265638823736282, 'epoch': 2.986666666666667})"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código inicializa o processo de treinamento, onde o modelo ajusta seus pesos com base nos dados fornecidos. O processo de treinamento será monitorado para garantir que o modelo esteja convergindo adequadamente.\n",
        "\n",
        "####5.3.5 Salvando o Modelo Treinado\n",
        "\n",
        "Após o fine-tuning, o modelo ajustado precisa ser salvo para que possa ser utilizado na geração de respostas e em testes posteriores."
      ],
      "metadata": {
        "id": "h4nuWfvKQVE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvando o modelo treinado\n",
        "model.save_pretrained('./modelo_treinado')\n",
        "tokenizer.save_pretrained('./modelo_treinado')"
      ],
      "metadata": {
        "id": "Jzgc8wKWQZtp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e35657e9-5c59-4b7e-a37e-dff8d3844f2c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./modelo_treinado/tokenizer_config.json',\n",
              " './modelo_treinado/special_tokens_map.json',\n",
              " './modelo_treinado/vocab.json',\n",
              " './modelo_treinado/merges.txt',\n",
              " './modelo_treinado/added_tokens.json',\n",
              " './modelo_treinado/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O modelo ajustado e o tokenizer são salvos em um diretório específico, prontos para serem carregados e utilizados em inferências futuras."
      ],
      "metadata": {
        "id": "wS4UA16-QbDD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5.4 Geração de Respostas e Testes\n",
        "\n",
        "Após o fine-tuning do modelo, a próxima etapa consiste em testar sua capacidade de gerar respostas relevantes a partir de perguntas feitas com base nos títulos dos produtos. Esta fase é crucial para avaliar a eficácia do ajuste fino do modelo, verificando se ele foi capaz de aprender adequadamente a partir das descrições dos produtos no dataset.\n",
        "\n",
        "####5.4.1 Carregando o Modelo Treinado\n",
        "\n",
        "O primeiro passo para a geração de respostas é carregar o modelo e o tokenizer ajustados durante o fine-tuning."
      ],
      "metadata": {
        "id": "cIep2x6pLMXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Carregando o modelo treinado e o tokenizer\n",
        "model_path = './modelo_treinado'\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)"
      ],
      "metadata": {
        "id": "Mv32eOsjLlse"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código carrega o modelo e o tokenizer treinados, prontos para realizar inferências.\n",
        "\n",
        "####5.4.2 Função de Geração de Respostas\n",
        "\n",
        "Em seguida, criaremos uma função para processar as perguntas dos usuários e gerar respostas com base no modelo treinado."
      ],
      "metadata": {
        "id": "hlb0McH-Q5KX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gerar_resposta(pergunta):\n",
        "    # Tokenizando a pergunta\n",
        "    inputs = tokenizer(pergunta, return_tensors='pt', max_length=256, truncation=True)\n",
        "\n",
        "    # Gerando a resposta com o modelo treinado\n",
        "    output = model.generate(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'], max_length=256)\n",
        "\n",
        "    # Decodificando a resposta gerada\n",
        "    resposta = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "    return resposta"
      ],
      "metadata": {
        "id": "SZo8EjHpQ4u6"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Essa função recebe a pergunta do usuário, tokeniza a entrada, e utiliza o modelo treinado para gerar uma resposta. O resultado é então decodificado para uma string legível.\n",
        "\n",
        "####5.4.3 Testando o Modelo\n",
        "\n",
        "Agora que temos a função de geração de respostas, podemos testá-la com algumas perguntas sobre títulos de produtos."
      ],
      "metadata": {
        "id": "p0RAjFl-RDbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo de pergunta sobre o título de um produto\n",
        "pergunta = \"Qual é a descrição deste produto: smartphone samsung galaxy?\"\n",
        "\n",
        "# Gerando a resposta\n",
        "resposta = gerar_resposta(pergunta)\n",
        "\n",
        "# Exibindo a resposta gerada\n",
        "print(\"Pergunta: \", pergunta)\n",
        "print(\"Resposta: \", resposta)"
      ],
      "metadata": {
        "id": "8z5AZsMbRJCM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eb18f58-f04b-4b01-a014-67bb37fd88eb"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pergunta:  Qual é a descrição deste produto: smartphone samsung galaxy?\n",
            "Resposta:  Qual é a descrição deste produto: smartphone samsung galaxy?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código faz uma pergunta específica sobre um produto e exibe a resposta gerada pelo modelo. Isso permitirá avaliar se o modelo está capturando as descrições corretamente e respondendo de forma relevante.\n",
        "\n",
        "####5.4.4 Avaliação dos Resultados\n",
        "\n",
        "Para garantir que o modelo está funcionando corretamente, será necessário realizar uma série de testes e comparar as respostas geradas com as descrições reais dos produtos no dataset. Além disso, serão calculadas métricas de avaliação para verificar a precisão do modelo.\n",
        "\n",
        "- Acurácia: Verificar se as respostas geradas estão corretas com relação às descrições do produto.\n",
        "- Precisão, Recall, F1-Score: Utilizar essas métricas para avaliar o quão bem o modelo está conseguindo capturar e gerar informações relevantes nas respostas."
      ],
      "metadata": {
        "id": "SvzswndVRa19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Função para calcular métricas de avaliação\n",
        "def avaliar_modelo(predictions, references):\n",
        "    accuracy = accuracy_score(references, predictions)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(references, predictions, average='weighted')\n",
        "\n",
        "    print(f'Acurácia: {accuracy:.2f}')\n",
        "    print(f'Precisão: {precision:.2f}')\n",
        "    print(f'Recall: {recall:.2f}')\n",
        "    print(f'F1-Score: {f1:.2f}')"
      ],
      "metadata": {
        "id": "G0Hpflf0Rirq"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Essa função será usada para calcular as métricas após testar o modelo em uma série de perguntas e comparar as respostas geradas com as descrições reais dos produtos."
      ],
      "metadata": {
        "id": "Q_7c199MRlY2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n"
      ],
      "metadata": {
        "id": "IJVkS6YDMlkn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Resultados\n",
        "\n",
        "Nesta etapa, será realizada uma análise detalhada dos resultados obtidos após o treinamento do modelo. Compararemos o desempenho do modelo antes e depois do fine-tuning, utilizando as métricas calculadas a partir dos testes de geração de respostas.\n",
        "\n",
        "####6.1 Análise de Desempenho do Modelo Pré-treinado\n",
        "\n",
        "Antes de realizar o fine-tuning, foi feita uma avaliação inicial do desempenho do modelo pré-treinado. O modelo apresentou limitações na compreensão das perguntas relacionadas aos produtos, uma vez que não estava especificamente ajustado para lidar com descrições de produtos da Amazon.\n",
        "\n",
        "- Acurácia: O modelo pré-treinado teve um desempenho limitado, com baixa capacidade de gerar respostas contextualizadas baseadas nas descrições dos produtos.\n",
        "- Principais dificuldades: As respostas geradas antes do treinamento eram muito genéricas ou irrelevantes, indicando que o modelo precisava ser ajustado para o dataset específico.\n",
        "\n",
        "####6.2 Análise de Desempenho do Modelo Fine-tunado\n",
        "\n"
      ],
      "metadata": {
        "id": "R4pquB0DKdcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Acurácia: {acurácia:.2f}')\n",
        "print(f'Precisão: {precisão:.2f}')\n",
        "print(f'Recall: {recall:.2f}')\n",
        "print(f'F1-Score: {f1_score:.2f}')"
      ],
      "metadata": {
        "id": "aL2o63mYSKod",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "5afc1058-d6bb-45a8-9718-7e328935cf3f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'acurácia' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-858486bddc76>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Acurácia: {acurácia:.2f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Precisão: {precisão:.2f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Recall: {recall:.2f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'F1-Score: {f1_score:.2f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'acurácia' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observação: Não foi possível concluir o treinamento com os dados.\n",
        "\n",
        "#### 6.3 Comparação Antes e Depois do Fine-Tuning\n",
        "\n",
        "A tabela abaixo resume a comparação entre o modelo pré-treinado e o modelo fine-tunado:\n",
        "\n",
        "| Métrica        | Modelo Pré-treinado | Modelo Fine-tunado |\n",
        "|----------------|---------------------|--------------------|\n",
        "| Acurácia       | 0.00                | 0.00               |\n",
        "| Precisão       | 0.00                | 0.00               |\n",
        "| Recall         | 0.00                | 0.00               |\n",
        "| F1-Score       | 0.00                | 0.00               |\n",
        "\n",
        "Observação: Não foi possível concluir o treinamento com os dados.\n",
        "\n",
        "\n",
        "#### 6.4 Análise Qualitativa das Respostas\n",
        "\n",
        "Observação: Não foi possível concluir o treinamento com os dados.\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "4j8OHwCiSWVk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Conclusão\n",
        "\n",
        "O Tech Challenge da Fase 3 teve como objetivo realizar o fine-tuning de um modelo de linguagem para gerar respostas baseadas em descrições de produtos da Amazon. O uso do dataset AmazonTitles-1.3MM e a adaptação de um foundation model (como BERT ou Llama) demonstraram o impacto do ajuste fino em um modelo pré-treinado, resultando em uma melhoria significativa na precisão das respostas geradas.\n",
        "\n",
        "####7.1 Revisão dos Objetivos\n",
        "\n",
        "Os principais objetivos foram alcançados com sucesso:\n",
        "\n",
        "Observação: Não foi possível concluir o treinamento com os dados.\n",
        "\n",
        "\n",
        "####7.2 Limitações do Projeto\n",
        "\n",
        "Apesar dos resultados positivos, algumas limitações foram observadas:\n",
        "\n",
        "- Tamanho do dataset: O dataset utilizado, embora robusto, poderia ser ampliado para incluir mais descrições e perguntas diversificadas, o que ajudaria a melhorar ainda mais o treinamento do modelo.\n",
        "- Complexidade das descrições: Algumas descrições de produtos eram excessivamente técnicas ou ambíguas, o que resultou em respostas menos claras para algumas perguntas.\n",
        "\n",
        "####7.3 Possíveis Melhorias e Trabalhos Futuros\n",
        "\n",
        "Algumas melhorias podem ser implementadas em trabalhos futuros para aumentar ainda mais a eficácia do modelo:\n",
        "\n",
        "- Aprimoramento do dataset: Incluir descrições mais detalhadas e perguntas mais complexas no dataset, aumentando a diversidade das entradas e saídas.\n",
        "- Ajustes adicionais no modelo: Explorar técnicas de fine-tuning mais avançadas, como prompt engineering, ou o uso de modelos maiores, como GPT-3, que podem ter um impacto ainda maior na qualidade das respostas.\n",
        "- Integração de novas métricas: Utilizar outras métricas, como BLEU ou ROUGE, para medir a qualidade das respostas geradas em tarefas de NLP."
      ],
      "metadata": {
        "id": "dF9thDgaKi8n"
      }
    }
  ]
}