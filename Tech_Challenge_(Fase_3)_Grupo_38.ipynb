{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm",
      "mount_file_id": "1rmMsimThUdMOvd3vYzqdp7I0nTBP_Pr9",
      "authorship_tag": "ABX9TyMLMO1x9LPfrOKi5epDUz/U"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2bb4eb61f6474d4ab863dbd2f348064c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d77ebd0f5a54bd1a9b67970e844ecd0",
              "IPY_MODEL_591540dfd76a4319a396166854eb09d9",
              "IPY_MODEL_71e1ded379394184bd6ed62c04bb1fbd"
            ],
            "layout": "IPY_MODEL_4121b26b63644f1089b5225f174c67a5"
          }
        },
        "8d77ebd0f5a54bd1a9b67970e844ecd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17a94668ca9642d28a20e5ab6bb7df69",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b8b836f25a7644fd96c20cdf1484a01d",
            "value": "Map:â€‡100%"
          }
        },
        "591540dfd76a4319a396166854eb09d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c5ad1af5ef44e258f3f0f568e62aa89",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9b30223cb964a1e8e1f2bc2e785e373",
            "value": 10000
          }
        },
        "71e1ded379394184bd6ed62c04bb1fbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62dd7d3a93524c22b3006ab3e8db7e56",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b9cda97674624be2bb1366f151e9f424",
            "value": "â€‡10000/10000â€‡[00:02&lt;00:00,â€‡3497.06â€‡examples/s]"
          }
        },
        "4121b26b63644f1089b5225f174c67a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17a94668ca9642d28a20e5ab6bb7df69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8b836f25a7644fd96c20cdf1484a01d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c5ad1af5ef44e258f3f0f568e62aa89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9b30223cb964a1e8e1f2bc2e785e373": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "62dd7d3a93524c22b3006ab3e8db7e56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9cda97674624be2bb1366f151e9f424": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Tech Challenge - FIAP: IA para Devs (Fase 3)\n",
        "\n",
        "###Grupo 38\n",
        "- Pedro Vianna Silveira\n",
        "- Rafael Silva Souza\n",
        "- Rodrigo de Freitas Ornellas\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”— CÃ³digo Github\n",
        "\n",
        "\n",
        "\n",
        "https://github.com/rafael2mind/tech-challenge-fase-3\n",
        "\n",
        "\n",
        "### ðŸ”— VÃ­deo de apresentaÃ§Ã£o\n",
        "https://youtu.be/\n",
        "\n",
        "---\n",
        "\n",
        "### 1. IntroduÃ§Ã£o\n",
        "\n",
        "#### Contexto e MotivaÃ§Ã£o\n",
        "\n",
        "Nesta fase do Tech Challenge, o foco estÃ¡ em realizar o fine-tuning de um foundation model (como BERT, Llama, Mistral, etc.) utilizando o dataset AmazonTitles-1.3MM. O objetivo Ã© treinar o modelo para responder perguntas dos usuÃ¡rios com base nas descriÃ§Ãµes de produtos fornecidas no dataset.\n",
        "\n",
        "O dataset AmazonTitles-1.3MM contÃ©m consultas textuais reais de usuÃ¡rios sobre produtos da Amazon, associadas a tÃ­tulos de produtos e suas respectivas descriÃ§Ãµes. Com o aumento das interaÃ§Ãµes em plataformas de e-commerce, hÃ¡ uma crescente necessidade de sistemas que consigam entender perguntas dos usuÃ¡rios e gerar respostas relevantes, utilizando descriÃ§Ãµes detalhadas dos produtos.\n",
        "\n",
        "Este projeto propÃµe a construÃ§Ã£o de um sistema onde, a partir de uma pergunta do usuÃ¡rio sobre um tÃ­tulo de produto, o modelo serÃ¡ capaz de gerar uma resposta adequada, utilizando o conhecimento adquirido no processo de fine-tuning com o dataset.\n",
        "\n",
        "\n",
        "#### Objetivos do Projeto\n",
        "\n",
        "O principal objetivo deste projeto Ã© realizar o fine-tuning de um modelo de linguagem com o dataset AmazonTitles-1.3MM para permitir que o modelo:\n",
        "\n",
        "1. Gere respostas baseadas nas descriÃ§Ãµes dos produtos: A partir de uma pergunta feita pelo usuÃ¡rio sobre o tÃ­tulo de um produto, o modelo deverÃ¡ gerar uma resposta utilizando as descriÃ§Ãµes presentes no dataset.\n",
        "2. Melhore a precisÃ£o e relevÃ¢ncia das respostas: O fine-tuning do modelo deve permitir uma compreensÃ£o mais profunda das relaÃ§Ãµes entre o tÃ­tulo e a descriÃ§Ã£o de um produto, resultando em respostas mais informativas e Ãºteis para o usuÃ¡rio.\n",
        "3. Documente o processo de ajuste fino: Descrever detalhadamente as etapas de prÃ©-processamento de dados, ajuste de hiperparÃ¢metros e qualquer modificaÃ§Ã£o feita ao modelo durante o treinamento.\n",
        "\n",
        "\n",
        "#### Estrutura do Projeto\n",
        "\n",
        "O projeto serÃ¡ desenvolvido em vÃ¡rias etapas, conforme detalhado a seguir:\n",
        "\n",
        "1. **IntroduÃ§Ã£o**:\n",
        "   - ContextualizaÃ§Ã£o do problema.\n",
        "   - Objetivos do projeto: foco no fine-tuning de um foundation model (como BERT, Llama, Mistral) utilizando o dataset AmazonTitles-1.3MM para gerar respostas baseadas em descriÃ§Ãµes de produtos.\n",
        "\n",
        "2. **DescriÃ§Ã£o do Problema**:\n",
        "   - DefiniÃ§Ã£o do problema: necessidade de sistemas de NLP capazes de gerar respostas baseadas nas descriÃ§Ãµes de produtos.\n",
        "   - ImportÃ¢ncia do problema no contexto de plataformas de e-commerce.\n",
        "   - Abordagem para a resoluÃ§Ã£o do problema.\n",
        "\n",
        "3. **FundamentaÃ§Ã£o TeÃ³rica**:\n",
        "   - Modelos de linguagem (foundation models) como BERT, Llama, Mistral.\n",
        "   - Fine-tuning: tÃ©cnica de ajuste fino do modelo para tarefas especÃ­ficas.\n",
        "   - PrÃ©-processamento de dados textuais: tokenizaÃ§Ã£o, normalizaÃ§Ã£o, remoÃ§Ã£o de stop words.\n",
        "   - GeraÃ§Ã£o de respostas em NLP.\n",
        "\n",
        "4. **Metodologia**:\n",
        "   - **PreparaÃ§Ã£o dos Dados**: Carregamento do dataset AmazonTitles-1.3MM e prÃ©-processamento, incluindo limpeza e criaÃ§Ã£o de prompts.\n",
        "   - **SeleÃ§Ã£o e ConfiguraÃ§Ã£o do Modelo**: Escolha de um modelo adequado (BERT, Llama, etc.) e tokenizaÃ§Ã£o dos dados.\n",
        "   - **ExecuÃ§Ã£o do Fine-Tuning**: ConfiguraÃ§Ã£o de hiperparÃ¢metros, treinamento do modelo e ajustes ao longo do processo.\n",
        "   - **AvaliaÃ§Ã£o e ValidaÃ§Ã£o**: Teste do modelo treinado e comparaÃ§Ã£o com o modelo prÃ©-treinado.\n",
        "\n",
        "5. **ImplementaÃ§Ã£o**:\n",
        "   - DescriÃ§Ã£o do ambiente de desenvolvimento: ferramentas como Google Colab, bibliotecas como Transformers, Pandas, NumPy, Matplotlib, TensorFlow ou PyTorch.\n",
        "   - **Carregamento e PreparaÃ§Ã£o do Dataset**: CÃ³digo de carregamento, limpeza e tokenizaÃ§Ã£o dos dados.\n",
        "   - **Fine-tuning do Modelo Escolhido**: ExecuÃ§Ã£o do ajuste fino e salvamento do modelo treinado.\n",
        "   - **GeraÃ§Ã£o de Respostas e Testes**: FunÃ§Ã£o para gerar respostas a partir de perguntas, avaliaÃ§Ã£o de mÃ©tricas como acurÃ¡cia e F1-score.\n",
        "\n",
        "6. **Resultados**:\n",
        "   - AnÃ¡lise comparativa do modelo prÃ©-treinado e fine-tunado.\n",
        "   - MÃ©tricas de avaliaÃ§Ã£o e discussÃ£o dos resultados obtidos.\n",
        "   - AnÃ¡lise qualitativa das respostas geradas pelo modelo.\n",
        "\n",
        "7. **ConclusÃ£o**:\n",
        "   - RevisÃ£o dos objetivos e resultados.\n",
        "   - LimitaÃ§Ãµes do projeto e sugestÃµes de melhorias para trabalhos futuros.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "VUGPK79JEHwp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. DescriÃ§Ã£o do Problema\n",
        "\n",
        "#### DefiniÃ§Ã£o do Problema\n",
        "\n",
        "Neste Tech Challenge, o problema central Ã© realizar o **fine-tuning** de um **foundation model** (como Llama, BERT, ou Mistral) utilizando o dataset **AmazonTitles-1.3MM**, que contÃ©m perguntas feitas por usuÃ¡rios sobre produtos da Amazon e suas respectivas descriÃ§Ãµes. O objetivo Ã© treinar o modelo para gerar respostas relevantes a partir dessas descriÃ§Ãµes, com base em perguntas relacionadas aos tÃ­tulos dos produtos.\n",
        "\n",
        "A tarefa proposta envolve construir um sistema que possa compreender o contexto de uma pergunta do usuÃ¡rio, buscar informaÃ§Ãµes adequadas nas descriÃ§Ãµes dos produtos e retornar uma resposta que seja ao mesmo tempo precisa e informativa. Isso exige um fine-tuning cuidadoso do modelo para adaptar seu conhecimento Ã s caracterÃ­sticas especÃ­ficas do dataset.\n",
        "\n",
        "#### ImportÃ¢ncia\n",
        "\n",
        "O desenvolvimento de modelos de linguagem que consigam responder de maneira precisa e contextualizada Ã© essencial para plataformas de e-commerce, como a Amazon, onde a interaÃ§Ã£o dos usuÃ¡rios com o sistema muitas vezes depende de respostas rÃ¡pidas e relevantes. Ao utilizar descriÃ§Ãµes detalhadas dos produtos, o modelo pode melhorar significativamente a experiÃªncia do usuÃ¡rio ao fornecer informaÃ§Ãµes que auxiliam nas decisÃµes de compra.\n",
        "\n",
        "AlÃ©m disso, este tipo de sistema pode ser escalado para vÃ¡rias outras plataformas, onde a compreensÃ£o do contexto e a geraÃ§Ã£o de respostas personalizadas sÃ£o crÃ­ticas para o sucesso de uma interaÃ§Ã£o automatizada.\n",
        "\n",
        "#### Objetivos e CritÃ©rios de Sucesso\n",
        "\n",
        "Os principais objetivos deste desafio incluem:\n",
        "- **Treinar um modelo de linguagem** capaz de responder a perguntas de usuÃ¡rios com base nas descriÃ§Ãµes de produtos.\n",
        "- **Melhorar a precisÃ£o e a relevÃ¢ncia das respostas** fornecidas pelo modelo apÃ³s o fine-tuning.\n",
        "- **Documentar o processo de treinamento e ajustes** do modelo, garantindo a replicabilidade.\n",
        "\n",
        "CritÃ©rios de sucesso:\n",
        "- **AcurÃ¡cia nas respostas**: O modelo deverÃ¡ ser capaz de gerar respostas precisas e informativas, com base no contexto dado pela pergunta e nas descriÃ§Ãµes dos produtos.\n",
        "- **EficiÃªncia do treinamento**: O modelo deverÃ¡ ser treinado com parÃ¢metros otimizados para garantir um tempo de resposta rÃ¡pido e uma geraÃ§Ã£o de respostas de alta qualidade.\n",
        "- **Escalabilidade**: O sistema deve ser capaz de lidar com um grande volume de perguntas e descriÃ§Ãµes, mantendo a eficiÃªncia e qualidade.\n",
        "\n",
        "#### Abordagem para a ResoluÃ§Ã£o do Problema\n",
        "\n",
        "A abordagem para resolver o problema envolve as seguintes etapas:\n",
        "1. **PreparaÃ§Ã£o dos Dados**: Extrair e prÃ©-processar os dados relevantes do dataset **AmazonTitles-1.3MM** (colunas de tÃ­tulo e descriÃ§Ã£o), garantindo que estejam em um formato adequado para o fine-tuning do modelo.\n",
        "2. **SeleÃ§Ã£o do Modelo**: Escolher um **foundation model** que seja adequado para a tarefa de geraÃ§Ã£o de respostas com base em descriÃ§Ãµes de produtos.\n",
        "3. **Fine-Tuning**: Ajustar o modelo utilizando o dataset preparado, otimizando os hiperparÃ¢metros para garantir a melhor performance possÃ­vel.\n",
        "4. **Testes e AvaliaÃ§Ã£o**: Testar o modelo treinado com um conjunto de perguntas para verificar a qualidade e precisÃ£o das respostas geradas. A performance serÃ¡ comparada com o estado inicial do modelo antes do fine-tuning.\n",
        "5. **AnÃ¡lise dos Resultados**: Avaliar os resultados obtidos e verificar se os critÃ©rios de sucesso foram atingidos, documentando possÃ­veis melhorias e ajustes para o futuro.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "2obifMY3HMWZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. FundamentaÃ§Ã£o TeÃ³rica\n",
        "\n",
        "Nesta seÃ§Ã£o, serÃ£o apresentados os principais conceitos teÃ³ricos que embasam a execuÃ§Ã£o do projeto, com foco em modelos de linguagem, fine-tuning, e prÃ©-processamento de dados textuais.\n",
        "\n",
        "#### 3.1 Modelos de Linguagem (Foundation Models)\n",
        "\n",
        "**Modelos de linguagem**, como **BERT (Bidirectional Encoder Representations from Transformers)** e **Llama**, sÃ£o algoritmos projetados para processar e compreender a linguagem natural. Esses modelos sÃ£o baseados em arquiteturas de redes neurais profundas, em particular os **Transformers**, que utilizam mecanismos de atenÃ§Ã£o para capturar a relaÃ§Ã£o entre palavras e frases em um texto. A principal vantagem dos Transformers em relaÃ§Ã£o a outros modelos mais antigos, como as redes recorrentes (RNNs), Ã© a sua capacidade de processar grandes quantidades de dados em paralelo, preservando o contexto das palavras independentemente da posiÃ§Ã£o em que elas aparecem no texto.\n",
        "\n",
        "Esses modelos sÃ£o chamados de **foundation models** porque servem como ponto de partida para vÃ¡rias tarefas de **NLP (Natural Language Processing)**, como geraÃ§Ã£o de texto, traduÃ§Ã£o, sumarizaÃ§Ã£o e resposta a perguntas. No contexto deste projeto, o fine-tuning de um modelo de linguagem permitirÃ¡ que ele gere respostas baseadas em descriÃ§Ãµes de produtos, ajustando seu conhecimento prÃ©vio para uma tarefa especÃ­fica.\n",
        "\n",
        "#### 3.2 Fine-Tuning\n",
        "\n",
        "O processo de **fine-tuning** Ã© uma tÃ©cnica de transferÃªncia de aprendizado. Ele envolve o ajuste fino de um modelo prÃ©-treinado em um grande corpus de dados (como BERT ou Llama) para uma tarefa mais especÃ­fica, utilizando um conjunto de dados especializado. Em vez de treinar um modelo do zero, o fine-tuning aproveita o conhecimento que o modelo jÃ¡ adquiriu durante seu treinamento original e o adapta para resolver um problema especÃ­fico.\n",
        "\n",
        "No caso deste trabalho, o fine-tuning serÃ¡ realizado no **foundation model** utilizando o dataset **AmazonTitles-1.3MM**, composto por tÃ­tulos e descriÃ§Ãµes de produtos. Isso permitirÃ¡ que o modelo aprenda a responder perguntas dos usuÃ¡rios sobre os produtos, com base nas descriÃ§Ãµes detalhadas.\n",
        "\n",
        "#### 3.3 PrÃ©-Processamento de Dados Textuais\n",
        "\n",
        "O **prÃ©-processamento de dados textuais** Ã© uma etapa crucial para o sucesso de qualquer modelo de NLP. Esse processo inclui vÃ¡rias tÃ©cnicas que garantem que os dados estejam limpos e em um formato adequado para serem utilizados no treinamento do modelo. As principais tÃ©cnicas de prÃ©-processamento incluem:\n",
        "\n",
        "- **TokenizaÃ§Ã£o**: Dividir o texto em unidades menores, como palavras ou subpalavras, que serÃ£o utilizadas como input para o modelo.\n",
        "- **NormalizaÃ§Ã£o**: Convertendo todos os caracteres para minÃºsculas, removendo pontuaÃ§Ãµes e aplicando stemming ou lematizaÃ§Ã£o para reduzir palavras Ã  sua forma bÃ¡sica.\n",
        "- **RemoÃ§Ã£o de Stop Words**: Stop words sÃ£o palavras comuns, como artigos e preposiÃ§Ãµes, que muitas vezes sÃ£o removidas para reduzir a complexidade do texto sem perder o significado.\n",
        "\n",
        "Essas etapas sÃ£o fundamentais para garantir que o dataset **AmazonTitles-1.3MM** esteja em um formato otimizado para o fine-tuning do modelo.\n",
        "\n",
        "#### 3.4 GeraÃ§Ã£o de Respostas em NLP\n",
        "\n",
        "A **geraÃ§Ã£o de respostas** em sistemas de NLP refere-se Ã  capacidade de um modelo de linguagem gerar uma resposta coerente e relevante a partir de uma entrada fornecida pelo usuÃ¡rio. Este tipo de tarefa Ã© amplamente utilizado em sistemas de atendimento ao cliente, chatbots e assistentes virtuais. No caso deste projeto, o objetivo Ã© treinar o modelo para que, a partir de uma pergunta sobre o tÃ­tulo de um produto, ele seja capaz de gerar uma resposta baseada na descriÃ§Ã£o contida no dataset.\n",
        "\n",
        "Modelos que realizam **geraÃ§Ã£o de respostas** utilizam tanto tÃ©cnicas de aprendizado supervisionado quanto aprendizado nÃ£o supervisionado, com o intuito de generalizar e inferir respostas que sejam adequadas ao contexto fornecido.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "JX5DslD6HvD-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Metodologia\n",
        "\n",
        "Nesta seÃ§Ã£o, serÃ¡ detalhada a metodologia adotada para a implementaÃ§Ã£o do projeto. A abordagem segue uma sequÃªncia estruturada, desde a preparaÃ§Ã£o dos dados atÃ© o fine-tuning do modelo, passando pelos processos de avaliaÃ§Ã£o e testes.\n",
        "\n",
        "#### 4.1 PreparaÃ§Ã£o dos Dados\n",
        "\n",
        "A primeira etapa do projeto serÃ¡ a **preparaÃ§Ã£o do dataset** **AmazonTitles-1.3MM**. Esse processo envolverÃ¡:\n",
        "\n",
        "- **Carregamento do Dataset**: O arquivo **\"trn.json\"** serÃ¡ lido e explorado, focando nas colunas relevantes para o fine-tuning: **\"title\"** (tÃ­tulo do produto) e **\"content\"** (descriÃ§Ã£o do produto).\n",
        "- **Limpeza e NormalizaÃ§Ã£o dos Dados**: SerÃ¡ realizada a remoÃ§Ã£o de inconsistÃªncias e duplicatas nos dados. Os textos das descriÃ§Ãµes passarÃ£o por um processo de normalizaÃ§Ã£o, que inclui a remoÃ§Ã£o de caracteres especiais, tokenizaÃ§Ã£o, e a padronizaÃ§Ã£o de caixa (minÃºsculas).\n",
        "- **CriaÃ§Ã£o de Prompts**: Para treinar o modelo, serÃ£o criados prompts que combinem perguntas baseadas nos tÃ­tulos dos produtos com as descriÃ§Ãµes correspondentes. Esses prompts servirÃ£o como entradas para o modelo durante o fine-tuning.\n",
        "\n",
        "#### 4.2 SeleÃ§Ã£o e ConfiguraÃ§Ã£o do Modelo\n",
        "\n",
        "A segunda etapa consiste na **seleÃ§Ã£o do foundation model** a ser utilizado para o fine-tuning. Entre as opÃ§Ãµes estÃ£o modelos populares como **BERT**, **Llama** ou **Mistral**, todos baseados em arquiteturas de transformers e conhecidos por seu desempenho em tarefas de NLP. A escolha serÃ¡ baseada na capacidade do modelo de lidar com grandes volumes de dados textuais e sua eficiÃªncia no processo de fine-tuning.\n",
        "\n",
        "- **PrÃ©-treino**: O modelo escolhido serÃ¡ avaliado antes do fine-tuning, utilizando uma parte do dataset para verificar sua performance inicial, estabelecendo uma base de comparaÃ§Ã£o.\n",
        "- **ConfiguraÃ§Ã£o de HiperparÃ¢metros**: SerÃ£o definidos os principais hiperparÃ¢metros, como taxa de aprendizado, nÃºmero de Ã©pocas, tamanho do lote, e otimizaÃ§Ãµes especÃ­ficas para o modelo, visando maximizar o desempenho durante o treinamento.\n",
        "\n",
        "#### 4.3 ExecuÃ§Ã£o do Fine-Tuning\n",
        "\n",
        "ApÃ³s a preparaÃ§Ã£o dos dados e a configuraÃ§Ã£o do modelo, serÃ¡ realizada a etapa de **fine-tuning**. Esse processo envolverÃ¡:\n",
        "\n",
        "- **Alimentar o Modelo com os Prompts Criados**: O modelo serÃ¡ treinado com os prompts que combinam perguntas sobre os tÃ­tulos dos produtos com as respostas esperadas, que sÃ£o as descriÃ§Ãµes correspondentes.\n",
        "- **Ajuste Fino dos HiperparÃ¢metros**: Durante o treinamento, os hiperparÃ¢metros serÃ£o ajustados conforme necessÃ¡rio para garantir a melhor performance possÃ­vel. Isso inclui ajustes na taxa de aprendizado e no nÃºmero de Ã©pocas, com base nas avaliaÃ§Ãµes realizadas apÃ³s cada ciclo de treinamento.\n",
        "- **DocumentaÃ§Ã£o do Processo**: Cada etapa do fine-tuning serÃ¡ documentada, incluindo os parÃ¢metros utilizados, os ajustes realizados, e os resultados intermediÃ¡rios obtidos apÃ³s cada ciclo de treinamento.\n",
        "\n",
        "#### 4.4 AvaliaÃ§Ã£o e ValidaÃ§Ã£o\n",
        "\n",
        "A etapa de **avaliaÃ§Ã£o** serÃ¡ crÃ­tica para verificar a eficiÃªncia do fine-tuning. O modelo serÃ¡ testado com um conjunto de perguntas relacionadas aos tÃ­tulos dos produtos, e as respostas geradas serÃ£o comparadas com as descriÃ§Ãµes esperadas.\n",
        "\n",
        "- **MÃ©tricas de AvaliaÃ§Ã£o**: SerÃ£o utilizadas mÃ©tricas como **acurÃ¡cia**, **precisÃ£o**, **recall**, e **F1-score** para medir a qualidade das respostas geradas pelo modelo. Esses indicadores ajudarÃ£o a verificar se o modelo foi capaz de aprender adequadamente com o dataset e se consegue gerar respostas relevantes.\n",
        "- **ComparaÃ§Ã£o Antes e Depois do Fine-Tuning**: Os resultados obtidos apÃ³s o fine-tuning serÃ£o comparados com a performance inicial do modelo, para quantificar a melhora na precisÃ£o das respostas.\n",
        "\n",
        "#### 4.5 IteraÃ§Ã£o e Refinamento\n",
        "\n",
        "Dependendo dos resultados da avaliaÃ§Ã£o, poderÃ¡ ser necessÃ¡rio realizar iteraÃ§Ãµes no processo de fine-tuning. Isso inclui:\n",
        "\n",
        "- **Reajuste de HiperparÃ¢metros**: Caso a performance do modelo nÃ£o seja satisfatÃ³ria, novos ajustes de hiperparÃ¢metros poderÃ£o ser feitos para otimizar os resultados.\n",
        "- **Refinamento dos Dados de Entrada**: Se o modelo apresentar dificuldades com certas perguntas ou tipos de descriÃ§Ãµes, pode ser necessÃ¡rio refinar a forma como os dados sÃ£o apresentados ao modelo, ajustando os prompts ou a estrutura do dataset.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "R6yHlhiUIVeR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. ImplementaÃ§Ã£o\n",
        "\n",
        "### 5.1 DescriÃ§Ã£o do Ambiente de Desenvolvimento (Ferramentas e Bibliotecas Utilizadas)\n",
        "\n",
        "Para a implementaÃ§Ã£o do projeto, serÃ¡ utilizado um ambiente de desenvolvimento composto por ferramentas e bibliotecas que facilitam o prÃ©-processamento dos dados, o treinamento do modelo e a avaliaÃ§Ã£o de resultados. Abaixo, segue uma descriÃ§Ã£o das principais tecnologias utilizadas:\n",
        "\n",
        "#### 5.1.1 Ferramentas\n",
        "\n",
        "- **Google Colab**: Utilizado como ambiente principal de desenvolvimento. O Google Colab fornece uma infraestrutura baseada em nuvem, com suporte para execuÃ§Ã£o de cÃ³digo Python, permitindo acesso a GPUs e TPUs para acelerar o processo de treinamento de modelos de deep learning.\n",
        "- **Python**: Linguagem de programaÃ§Ã£o principal utilizada no projeto, pela sua ampla adoÃ§Ã£o na Ã¡rea de aprendizado de mÃ¡quina e NLP (Natural Language Processing).\n",
        "- **GitHub**: Usado para o controle de versÃ£o e colaboraÃ§Ã£o entre os membros do grupo. Todo o cÃ³digo serÃ¡ versionado e armazenado em um repositÃ³rio pÃºblico ou privado no GitHub.\n",
        "\n",
        "#### 5.1.2 Bibliotecas\n",
        "\n",
        "- **Transformers** (da Hugging Face): Biblioteca utilizada para o carregamento e fine-tuning de modelos de linguagem como **BERT**, **Llama**, ou **Mistral**. Ela fornece uma interface fÃ¡cil para trabalhar com os principais modelos prÃ©-treinados e realizar ajustes finos.\n",
        "- **Pandas**: Usado para a manipulaÃ§Ã£o e anÃ¡lise dos dados do dataset **AmazonTitles-1.3MM**, permitindo a leitura e preparaÃ§Ã£o das colunas de tÃ­tulo e descriÃ§Ã£o do produto.\n",
        "- **NumPy**: Biblioteca fundamental para operaÃ§Ãµes matemÃ¡ticas e manipulaÃ§Ã£o de arrays, utilizada em conjunto com o Pandas para processamento de dados.\n",
        "- **Scikit-learn**: Utilizada para calcular mÃ©tricas de avaliaÃ§Ã£o como acurÃ¡cia, precisÃ£o, recall e F1-score, alÃ©m de fornecer ferramentas para dividir o dataset em conjuntos de treinamento e teste.\n",
        "\n",
        "#### 5.1.3 Infraestrutura\n",
        "\n",
        "- **GPU/TPU**: O uso de uma GPU ou TPU no Google Colab serÃ¡ crucial para acelerar o treinamento do modelo durante o fine-tuning, dado o grande volume de dados do dataset **AmazonTitles-1.3MM**.\n",
        "- **Armazenamento em Nuvem**: O Google Drive serÃ¡ utilizado para armazenar datasets e checkpoints dos modelos, garantindo que todo o progresso do treinamento seja salvo de forma segura e acessÃ­vel para futuras anÃ¡lises.\n"
      ],
      "metadata": {
        "id": "c5k7U0AXKMyD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5.2 CÃ³digo de Carregamento e PreparaÃ§Ã£o do Dataset\n",
        "\n",
        "Nesta etapa, serÃ¡ realizada a leitura do dataset AmazonTitles-1.3MM e o seu prÃ©-processamento, com o objetivo de estruturar os dados para o fine-tuning do modelo. O foco estarÃ¡ nas colunas de â€œtitleâ€ (tÃ­tulo do produto) e â€œcontentâ€ (descriÃ§Ã£o do produto), que serÃ£o usadas para construir os prompts que alimentarÃ£o o modelo.\n",
        "\n",
        "####5.2.1 Carregamento do Dataset"
      ],
      "metadata": {
        "id": "OjajeKZfLGq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Definindo o nÃºmero mÃ¡ximo de linhas a serem carregadas\n",
        "max_rows = 10000\n",
        "dataset_path = '/content/drive/MyDrive/Pos tech/fase 3/LF-Amazon-1.3M/trn.json'\n",
        "\n",
        "# Carregando o dataset em pedaÃ§os e selecionando as primeiras 100 mil linhas\n",
        "df_chunks = pd.read_json(dataset_path, lines=True, chunksize=10000)\n",
        "df_limited = pd.concat([chunk for chunk in df_chunks][:max_rows // 10000], ignore_index=True)\n",
        "\n",
        "# Selecionando as colunas \"title\" e \"content\" (tÃ­tulo e descriÃ§Ã£o do produto)\n",
        "df_limited = df_limited[['title', 'content']]\n",
        "\n",
        "# Remover valores nulos\n",
        "df_limited.dropna(subset=['title', 'content'], inplace=True)\n",
        "\n",
        "# Limpeza bÃ¡sica: remover espaÃ§os em branco e converter para minÃºsculas\n",
        "df_limited['title'] = df_limited['title'].str.strip().str.lower()\n",
        "df_limited['content'] = df_limited['content'].str.strip().str.lower()\n",
        "\n",
        "# Visualizando o dataset apÃ³s a limpeza\n",
        "print(df_limited.head())"
      ],
      "metadata": {
        "id": "viM54RRgLkZM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94894590-acb8-4059-c28c-f72c5fee3b58"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               title  \\\n",
            "0                        girls ballet tutu neon pink   \n",
            "1                           adult ballet tutu yellow   \n",
            "2  the way things work: an illustrated encycloped...   \n",
            "3                                      mog's kittens   \n",
            "4                              misty of chincoteague   \n",
            "\n",
            "                                             content  \n",
            "0  high quality 3 layer ballet tutu. 12 inches in...  \n",
            "1                                                     \n",
            "2                                                     \n",
            "3  judith kerr&#8217;s best&#8211;selling adventu...  \n",
            "4                                                     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este cÃ³digo carrega o dataset AmazonTitles-1.3MM diretamente de um arquivo JSON e o converte em um DataFrame do Pandas para facilitar a manipulaÃ§Ã£o dos dados. A funÃ§Ã£o head() permite visualizar as primeiras linhas do dataset, garantindo que os dados foram carregados corretamente. Aqui a gente seleciona as colunas necessÃ¡rias, remove linhas com valores nulos e realiza uma limpeza bÃ¡sica nos textos, removendo espaÃ§os extras e convertendo os textos para letras minÃºsculas, o que ajuda a uniformizar os dados para o treinamento."
      ],
      "metadata": {
        "id": "BkRzrOUPOIp_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####5.2.3 CriaÃ§Ã£o de Prompts para o Fine-Tuning\n",
        "\n",
        "O prÃ³ximo passo Ã© criar os prompts que serÃ£o usados no fine-tuning do modelo. Cada prompt serÃ¡ formado por uma pergunta relacionada ao tÃ­tulo do produto, com a resposta sendo a descriÃ§Ã£o do produto."
      ],
      "metadata": {
        "id": "DS_m3pyyOsh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando prompts de perguntas e respostas para o fine-tuning no DataFrame limitado\n",
        "df_limited['prompt'] = 'Qual Ã© a descriÃ§Ã£o deste produto: ' + df_limited['title'] + '?'\n",
        "df_limited['response'] = df_limited['content']\n",
        "\n",
        "# Visualizando as colunas de prompt e resposta\n",
        "print(df_limited[['prompt', 'response']].head())"
      ],
      "metadata": {
        "id": "aJl8PhnUOzNv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d05dbfd9-aaf0-4096-c59f-55ff9decbdcb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              prompt  \\\n",
            "0  Qual Ã© a descriÃ§Ã£o deste produto: girls ballet...   \n",
            "1  Qual Ã© a descriÃ§Ã£o deste produto: adult ballet...   \n",
            "2  Qual Ã© a descriÃ§Ã£o deste produto: the way thin...   \n",
            "3   Qual Ã© a descriÃ§Ã£o deste produto: mog's kittens?   \n",
            "4  Qual Ã© a descriÃ§Ã£o deste produto: misty of chi...   \n",
            "\n",
            "                                            response  \n",
            "0  high quality 3 layer ballet tutu. 12 inches in...  \n",
            "1                                                     \n",
            "2                                                     \n",
            "3  judith kerr&#8217;s best&#8211;selling adventu...  \n",
            "4                                                     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este cÃ³digo cria a coluna prompt, onde cada linha contÃ©m uma pergunta sobre o tÃ­tulo do produto, e a coluna response, que contÃ©m a descriÃ§Ã£o do produto, que serÃ¡ a resposta esperada do modelo.\n",
        "\n",
        "####5.2.4 Salvando os Dados Preparados\n",
        "\n",
        "ApÃ³s a preparaÃ§Ã£o, os dados prontos para o treinamento podem ser salvos em um arquivo CSV ou em outro formato conveniente para uso posterior."
      ],
      "metadata": {
        "id": "hJvHVRhWO62w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvando o dataset preparado em um arquivo CSV\n",
        "df_limited.to_csv('dataset_preparado.csv', index=False)\n",
        "\n",
        "# OpÃ§Ã£o do JSON\n",
        "df_limited.to_json('dataset_preparado.json', orient='records', lines=True)"
      ],
      "metadata": {
        "id": "2wBV-YFlPBjV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esse trecho salva o dataset preparado em um arquivo CSV ou JSON, que serÃ¡ utilizado no treinamento do modelo de linguagem.\n"
      ],
      "metadata": {
        "id": "DVcGr12mPFP7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "###5.3 Fine-tuning do Modelo Escolhido\n",
        "\n",
        "Nesta etapa, o foco serÃ¡ realizar o fine-tuning do foundation model selecionado (por exemplo, BERT, Llama, ou Mistral) utilizando os dados previamente preparados. O fine-tuning consiste em ajustar os pesos do modelo para adaptar seu conhecimento geral ao problema especÃ­fico, que neste caso Ã© gerar respostas relacionadas a produtos da Amazon.\n",
        "\n",
        "####5.3.1 Importando o Modelo PrÃ©-treinado\n",
        "\n",
        "A primeira etapa do fine-tuning Ã© carregar o modelo prÃ©-treinado da biblioteca Transformers da Hugging Face, e configurÃ¡-lo para ser ajustado com os prompts que foram criados no prÃ©-processamento dos dados."
      ],
      "metadata": {
        "id": "BHKtHEpALKKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "login('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')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJVg3OJSq_h5",
        "outputId": "e0997d52-95ff-468d-e284-85c9430184aa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Verificando se o modelo e o tokenizer foram carregados corretamente\n",
        "print(\"Modelo e tokenizer GPT-2 carregados com sucesso.\")"
      ],
      "metadata": {
        "id": "VjgZAXBtLlBl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "261d5129-9a0e-4ee1-c2ab-f669c68d2ac3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo e tokenizer GPT-2 carregados com sucesso.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esse cÃ³digo carrega o tokenizer (responsÃ¡vel por converter o texto em tokens) e o modelo prÃ©-treinado que serÃ¡ ajustado para a tarefa especÃ­fica.\n",
        "\n",
        "####5.3.2 TokenizaÃ§Ã£o dos Dados\n",
        "\n",
        "Os prompts e respostas precisam ser convertidos em tokens para que o modelo possa processÃ¡-los durante o treinamento. Abaixo estÃ¡ o cÃ³digo que realiza essa conversÃ£o utilizando o tokenizer."
      ],
      "metadata": {
        "id": "BylJ0umXPhgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y datasets pyarrow\n",
        "!pip install datasets pyarrow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 895
        },
        "id": "ZZnyA04bsJGH",
        "outputId": "df7098b4-19e4-407a-d00e-74ad60da0c39"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: datasets 3.0.1\n",
            "Uninstalling datasets-3.0.1:\n",
            "  Successfully uninstalled datasets-3.0.1\n",
            "Found existing installation: pyarrow 17.0.0\n",
            "Uninstalling pyarrow-17.0.0:\n",
            "  Successfully uninstalled pyarrow-17.0.0\n",
            "Collecting datasets\n",
            "  Using cached datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting pyarrow\n",
            "  Using cached pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.6)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.12.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Using cached datasets-3.0.1-py3-none-any.whl (471 kB)\n",
            "Using cached pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "Installing collected packages: pyarrow, datasets\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.6.1 requires pyarrow<16.2.0a0,>=16.1.0, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.0.1 pyarrow-17.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "datasets",
                  "pyarrow"
                ]
              },
              "id": "792521cb5d194e8cad3e489aa31c5e99"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "# Definindo o token de padding para o tokenizer\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Convertendo o DataFrame para um Dataset do Hugging Face\n",
        "dataset = Dataset.from_pandas(df_limited)\n",
        "\n",
        "# FunÃ§Ã£o para tokenizar os prompts e respostas\n",
        "def tokenize_data(examples):\n",
        "    inputs = tokenizer(examples['prompt'], max_length=256, truncation=True, padding='max_length')\n",
        "    targets = tokenizer(examples['response'], max_length=256, truncation=True, padding='max_length')\n",
        "    return {'input_ids': inputs['input_ids'], 'attention_mask': inputs['attention_mask'], 'labels': targets['input_ids']}\n",
        "\n",
        "# Aplicando a tokenizaÃ§Ã£o no dataset\n",
        "tokenized_dataset = dataset.map(tokenize_data, batched=True)\n",
        "\n",
        "# Visualizando as primeiras entradas do dataset tokenizado\n",
        "print(tokenized_dataset[0])"
      ],
      "metadata": {
        "id": "GezQW3aaPrPO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "2bb4eb61f6474d4ab863dbd2f348064c",
            "8d77ebd0f5a54bd1a9b67970e844ecd0",
            "591540dfd76a4319a396166854eb09d9",
            "71e1ded379394184bd6ed62c04bb1fbd",
            "4121b26b63644f1089b5225f174c67a5",
            "17a94668ca9642d28a20e5ab6bb7df69",
            "b8b836f25a7644fd96c20cdf1484a01d",
            "4c5ad1af5ef44e258f3f0f568e62aa89",
            "c9b30223cb964a1e8e1f2bc2e785e373",
            "62dd7d3a93524c22b3006ab3e8db7e56",
            "b9cda97674624be2bb1366f151e9f424"
          ]
        },
        "outputId": "94f6c358-2910-4ca6-cf71-1b2a2083a929"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2bb4eb61f6474d4ab863dbd2f348064c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'title': 'girls ballet tutu neon pink', 'content': 'high quality 3 layer ballet tutu. 12 inches in length', 'prompt': 'Qual Ã© a descriÃ§Ã£o deste produto: girls ballet tutu neon pink?', 'response': 'high quality 3 layer ballet tutu. 12 inches in length', 'input_ids': [46181, 38251, 257, 1715, 380, 16175, 28749, 2244, 68, 40426, 9390, 25, 4813, 47735, 9732, 84, 25988, 11398, 30, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [8929, 3081, 513, 7679, 47735, 9732, 84, 13, 1105, 8331, 287, 4129, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Carregando o modelo GPT-2 prÃ©-treinado e o tokenizer\n",
        "model_name = 'gpt2'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "# Ajustando o pad_token_id para evitar os avisos\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# FunÃ§Ã£o para testar o modelo prÃ©-treinado com algumas amostras do dataset\n",
        "def test_pretrained_model(examples, num_samples=5):\n",
        "    print(\"Resultados do modelo GPT-2 prÃ©-treinado:\")\n",
        "\n",
        "    # Selecionando algumas amostras do dataset\n",
        "    samples = examples.select(range(num_samples))\n",
        "\n",
        "    for i, example in enumerate(samples):\n",
        "        # Gerando a entrada para o modelo\n",
        "        input_text = example['prompt']\n",
        "        inputs = tokenizer.encode(input_text, return_tensors='pt', padding=True, truncation=True)\n",
        "\n",
        "        # Gerando a saÃ­da do modelo\n",
        "        outputs = model.generate(inputs, max_length=100, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n",
        "        output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        print(f\"\\nAmostra {i+1}:\")\n",
        "        print(f\"Entrada: {input_text}\")\n",
        "        print(f\"SaÃ­da do modelo prÃ©-treinado: {output_text}\")\n",
        "\n",
        "# Amostras\n",
        "samples_to_test = tokenized_dataset.select(range(5))\n",
        "\n",
        "# Realizando o teste com o modelo prÃ©-treinado\n",
        "test_pretrained_model(samples_to_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXu11cF9Yu5j",
        "outputId": "55a5d025-ad98-4be6-9643-7ef6e88d2ac1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados do modelo GPT-2 prÃ©-treinado:\n",
            "\n",
            "Amostra 1:\n",
            "Entrada: Qual Ã© a descriÃ§Ã£o deste produto: girls ballet tutu neon pink?\n",
            "SaÃ­da do modelo prÃ©-treinado: Qual Ã© a descriÃ§Ã£o deste produto: girls ballet tutu neon pink?\n",
            "\n",
            "A: I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don\n",
            "\n",
            "Amostra 2:\n",
            "Entrada: Qual Ã© a descriÃ§Ã£o deste produto: adult ballet tutu yellow?\n",
            "SaÃ­da do modelo prÃ©-treinado: Qual Ã© a descriÃ§Ã£o deste produto: adult ballet tutu yellow?\n",
            "\n",
            "A: Yes, it is.\n",
            "\n",
            "B: Yes, it is.\n",
            "\n",
            "C: Yes, it is.\n",
            "\n",
            "D: Yes, it is.\n",
            "\n",
            "E: Yes, it is.\n",
            "\n",
            "F: Yes, it is.\n",
            "\n",
            "G: Yes, it is.\n",
            "\n",
            "H: Yes, it is.\n",
            "\n",
            "I: Yes, it is.\n",
            "\n",
            "\n",
            "Amostra 3:\n",
            "Entrada: Qual Ã© a descriÃ§Ã£o deste produto: the way things work: an illustrated encyclopedia of technology?\n",
            "SaÃ­da do modelo prÃ©-treinado: Qual Ã© a descriÃ§Ã£o deste produto: the way things work: an illustrated encyclopedia of technology?\n",
            "\n",
            "A: I think that the way things work is that we have to be able to understand the world around us. We have to be able to understand the world around us. We have to be able to understand the world around us. We have to be able to understand the world around us. We have to be able to understand the world around us. We have to be\n",
            "\n",
            "Amostra 4:\n",
            "Entrada: Qual Ã© a descriÃ§Ã£o deste produto: mog's kittens?\n",
            "SaÃ­da do modelo prÃ©-treinado: Qual Ã© a descriÃ§Ã£o deste produto: mog's kittens?\n",
            "\n",
            "Miguel: I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't know. I don't\n",
            "\n",
            "Amostra 5:\n",
            "Entrada: Qual Ã© a descriÃ§Ã£o deste produto: misty of chincoteague?\n",
            "SaÃ­da do modelo prÃ©-treinado: Qual Ã© a descriÃ§Ã£o deste produto: misty of chincoteague?\n",
            "\n",
            "A: I don't know. I don't know.\n",
            "\n",
            "Q: What is the difference between a \"chincoteague\" and a \"chimÃ©\" (chimÃ©)?\n",
            "\n",
            "A: The difference is that the chincoteague is a very small amount of sugar, whereas the chimÃ© is a very large amount of sugar.\n",
            "\n",
            "Q:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizamos os testes do modelo prÃ© treinado, de forma que foi possÃ­vel perceber a incapacidade do modelo de gerar respostas adequadas sem o fine-tuning.\n",
        "\n",
        "####5.3.3 ConfiguraÃ§Ã£o dos Argumentos de Treinamento\n",
        "\n",
        "A prÃ³xima etapa Ã© definir os parÃ¢metros do treinamento, como nÃºmero de Ã©pocas, taxa de aprendizado, e o uso de GPUs. Esses parÃ¢metros determinam a forma como o modelo serÃ¡ ajustado."
      ],
      "metadata": {
        "id": "dA6L06v7PwOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "# Ajustando os parÃ¢metros do treinamento\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    fp16=True,\n",
        "    gradient_accumulation_steps=8,\n",
        "    logging_steps=50,\n",
        "    save_steps=200,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        ")"
      ],
      "metadata": {
        "id": "CARKq1UwP25E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65be5cb1-c981-4d0d-e709-0daacc64c283"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este cÃ³digo configura os principais parÃ¢metros de treinamento, como o nÃºmero de Ã©pocas e o tamanho do lote, alÃ©m de definir a frequÃªncia de salvamento de checkpoints e de avaliaÃ§Ã£o do modelo.\n",
        "\n",
        "####5.3.4 Treinamento do Modelo\n",
        "\n",
        "Com os dados tokenizados e os parÃ¢metros configurados, o modelo estÃ¡ pronto para ser treinado. Abaixo estÃ¡ o cÃ³digo para executar o processo de fine-tuning utilizando a classe Trainer."
      ],
      "metadata": {
        "id": "Qt9fByf5P7_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividindo o dataset em 90% para treino e 10% para validaÃ§Ã£o\n",
        "train_test_split = tokenized_dataset.train_test_split(test_size=0.1)\n",
        "train_dataset = train_test_split['train']\n",
        "eval_dataset = train_test_split['test']\n",
        "\n",
        "# Importando o Trainer\n",
        "from transformers import Trainer\n",
        "\n",
        "# Criando o Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        ")\n",
        "\n",
        "# Iniciando o treinamento\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "dfkTwUwzQA-N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "d4dad069-ff74-45fe-ea93-0f5bef726787"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='420' max='420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [420/420 08:12, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>4.411900</td>\n",
              "      <td>4.352449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>4.292800</td>\n",
              "      <td>4.331074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>4.258600</td>\n",
              "      <td>4.334816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>4.290800</td>\n",
              "      <td>4.328104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>4.239900</td>\n",
              "      <td>4.330693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>4.261700</td>\n",
              "      <td>4.332803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>4.207700</td>\n",
              "      <td>4.332448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>4.164600</td>\n",
              "      <td>4.343865</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=420, training_loss=4.265638823736282, metrics={'train_runtime': 493.4157, 'train_samples_per_second': 54.721, 'train_steps_per_second': 0.851, 'total_flos': 3511764910080000.0, 'train_loss': 4.265638823736282, 'epoch': 2.986666666666667})"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este cÃ³digo inicializa o processo de treinamento, onde o modelo ajusta seus pesos com base nos dados fornecidos. O processo de treinamento serÃ¡ monitorado para garantir que o modelo esteja convergindo adequadamente.\n",
        "\n",
        "####5.3.5 Salvando o Modelo Treinado\n",
        "\n",
        "ApÃ³s o fine-tuning, o modelo ajustado precisa ser salvo para que possa ser utilizado na geraÃ§Ã£o de respostas e em testes posteriores."
      ],
      "metadata": {
        "id": "h4nuWfvKQVE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvando o modelo treinado\n",
        "model.save_pretrained('./modelo_treinado')\n",
        "tokenizer.save_pretrained('./modelo_treinado')"
      ],
      "metadata": {
        "id": "Jzgc8wKWQZtp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e35657e9-5c59-4b7e-a37e-dff8d3844f2c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./modelo_treinado/tokenizer_config.json',\n",
              " './modelo_treinado/special_tokens_map.json',\n",
              " './modelo_treinado/vocab.json',\n",
              " './modelo_treinado/merges.txt',\n",
              " './modelo_treinado/added_tokens.json',\n",
              " './modelo_treinado/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O modelo ajustado e o tokenizer sÃ£o salvos em um diretÃ³rio especÃ­fico, prontos para serem carregados e utilizados em inferÃªncias futuras."
      ],
      "metadata": {
        "id": "wS4UA16-QbDD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5.4 GeraÃ§Ã£o de Respostas e Testes\n",
        "\n",
        "ApÃ³s o fine-tuning do modelo, a prÃ³xima etapa consiste em testar sua capacidade de gerar respostas relevantes a partir de perguntas feitas com base nos tÃ­tulos dos produtos. Esta fase Ã© crucial para avaliar a eficÃ¡cia do ajuste fino do modelo, verificando se ele foi capaz de aprender adequadamente a partir das descriÃ§Ãµes dos produtos no dataset.\n",
        "\n",
        "####5.4.1 Carregando o Modelo Treinado\n",
        "\n",
        "O primeiro passo para a geraÃ§Ã£o de respostas Ã© carregar o modelo e o tokenizer ajustados durante o fine-tuning."
      ],
      "metadata": {
        "id": "cIep2x6pLMXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Carregando o modelo treinado e o tokenizer\n",
        "model_path = './modelo_treinado'\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)"
      ],
      "metadata": {
        "id": "Mv32eOsjLlse"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este cÃ³digo carrega o modelo e o tokenizer treinados, prontos para realizar inferÃªncias.\n",
        "\n",
        "####5.4.2 FunÃ§Ã£o de GeraÃ§Ã£o de Respostas\n",
        "\n",
        "Em seguida, criaremos uma funÃ§Ã£o para processar as perguntas dos usuÃ¡rios e gerar respostas com base no modelo treinado."
      ],
      "metadata": {
        "id": "hlb0McH-Q5KX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gerar_resposta(pergunta):\n",
        "    # Tokenizando a pergunta\n",
        "    inputs = tokenizer(pergunta, return_tensors='pt', max_length=256, truncation=True)\n",
        "\n",
        "    # Gerando a resposta com o modelo treinado\n",
        "    output = model.generate(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'], max_length=256)\n",
        "\n",
        "    # Decodificando a resposta gerada\n",
        "    resposta = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "    return resposta"
      ],
      "metadata": {
        "id": "SZo8EjHpQ4u6"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Essa funÃ§Ã£o recebe a pergunta do usuÃ¡rio, tokeniza a entrada, e utiliza o modelo treinado para gerar uma resposta. O resultado Ã© entÃ£o decodificado para uma string legÃ­vel.\n",
        "\n",
        "####5.4.3 Testando o Modelo\n",
        "\n",
        "Agora que temos a funÃ§Ã£o de geraÃ§Ã£o de respostas, podemos testÃ¡-la com algumas perguntas sobre tÃ­tulos de produtos."
      ],
      "metadata": {
        "id": "p0RAjFl-RDbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo de pergunta sobre o tÃ­tulo de um produto\n",
        "pergunta = \"Qual Ã© a descriÃ§Ã£o deste produto: smartphone samsung galaxy?\"\n",
        "\n",
        "# Gerando a resposta\n",
        "resposta = gerar_resposta(pergunta)\n",
        "\n",
        "# Exibindo a resposta gerada\n",
        "print(\"Pergunta: \", pergunta)\n",
        "print(\"Resposta: \", resposta)"
      ],
      "metadata": {
        "id": "8z5AZsMbRJCM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eb18f58-f04b-4b01-a014-67bb37fd88eb"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pergunta:  Qual Ã© a descriÃ§Ã£o deste produto: smartphone samsung galaxy?\n",
            "Resposta:  Qual Ã© a descriÃ§Ã£o deste produto: smartphone samsung galaxy?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este cÃ³digo faz uma pergunta especÃ­fica sobre um produto e exibe a resposta gerada pelo modelo. Isso permitirÃ¡ avaliar se o modelo estÃ¡ capturando as descriÃ§Ãµes corretamente e respondendo de forma relevante.\n",
        "\n",
        "####5.4.4 AvaliaÃ§Ã£o dos Resultados\n",
        "\n",
        "Para garantir que o modelo estÃ¡ funcionando corretamente, serÃ¡ necessÃ¡rio realizar uma sÃ©rie de testes e comparar as respostas geradas com as descriÃ§Ãµes reais dos produtos no dataset. AlÃ©m disso, serÃ£o calculadas mÃ©tricas de avaliaÃ§Ã£o para verificar a precisÃ£o do modelo.\n",
        "\n",
        "- AcurÃ¡cia: Verificar se as respostas geradas estÃ£o corretas com relaÃ§Ã£o Ã s descriÃ§Ãµes do produto.\n",
        "- PrecisÃ£o, Recall, F1-Score: Utilizar essas mÃ©tricas para avaliar o quÃ£o bem o modelo estÃ¡ conseguindo capturar e gerar informaÃ§Ãµes relevantes nas respostas."
      ],
      "metadata": {
        "id": "SvzswndVRa19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# FunÃ§Ã£o para calcular mÃ©tricas de avaliaÃ§Ã£o\n",
        "def avaliar_modelo(predictions, references):\n",
        "    accuracy = accuracy_score(references, predictions)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(references, predictions, average='weighted')\n",
        "\n",
        "    print(f'AcurÃ¡cia: {accuracy:.2f}')\n",
        "    print(f'PrecisÃ£o: {precision:.2f}')\n",
        "    print(f'Recall: {recall:.2f}')\n",
        "    print(f'F1-Score: {f1:.2f}')"
      ],
      "metadata": {
        "id": "G0Hpflf0Rirq"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Essa funÃ§Ã£o serÃ¡ usada para calcular as mÃ©tricas apÃ³s testar o modelo em uma sÃ©rie de perguntas e comparar as respostas geradas com as descriÃ§Ãµes reais dos produtos."
      ],
      "metadata": {
        "id": "Q_7c199MRlY2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n"
      ],
      "metadata": {
        "id": "IJVkS6YDMlkn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Resultados\n",
        "\n",
        "Nesta etapa, serÃ¡ realizada uma anÃ¡lise detalhada dos resultados obtidos apÃ³s o treinamento do modelo. Compararemos o desempenho do modelo antes e depois do fine-tuning, utilizando as mÃ©tricas calculadas a partir dos testes de geraÃ§Ã£o de respostas.\n",
        "\n",
        "####6.1 AnÃ¡lise de Desempenho do Modelo PrÃ©-treinado\n",
        "\n",
        "Antes de realizar o fine-tuning, foi feita uma avaliaÃ§Ã£o inicial do desempenho do modelo prÃ©-treinado. O modelo apresentou limitaÃ§Ãµes na compreensÃ£o das perguntas relacionadas aos produtos, uma vez que nÃ£o estava especificamente ajustado para lidar com descriÃ§Ãµes de produtos da Amazon.\n",
        "\n",
        "- AcurÃ¡cia: O modelo prÃ©-treinado teve um desempenho limitado, com baixa capacidade de gerar respostas contextualizadas baseadas nas descriÃ§Ãµes dos produtos.\n",
        "- Principais dificuldades: As respostas geradas antes do treinamento eram muito genÃ©ricas ou irrelevantes, indicando que o modelo precisava ser ajustado para o dataset especÃ­fico.\n",
        "\n",
        "####6.2 AnÃ¡lise de Desempenho do Modelo Fine-tunado\n",
        "\n"
      ],
      "metadata": {
        "id": "R4pquB0DKdcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'AcurÃ¡cia: {acurÃ¡cia:.2f}')\n",
        "print(f'PrecisÃ£o: {precisÃ£o:.2f}')\n",
        "print(f'Recall: {recall:.2f}')\n",
        "print(f'F1-Score: {f1_score:.2f}')"
      ],
      "metadata": {
        "id": "aL2o63mYSKod",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "5afc1058-d6bb-45a8-9718-7e328935cf3f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'acurÃ¡cia' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-858486bddc76>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'AcurÃ¡cia: {acurÃ¡cia:.2f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'PrecisÃ£o: {precisÃ£o:.2f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Recall: {recall:.2f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'F1-Score: {f1_score:.2f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'acurÃ¡cia' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ObservaÃ§Ã£o: NÃ£o foi possÃ­vel concluir o treinamento com os dados.\n",
        "\n",
        "#### 6.3 ComparaÃ§Ã£o Antes e Depois do Fine-Tuning\n",
        "\n",
        "A tabela abaixo resume a comparaÃ§Ã£o entre o modelo prÃ©-treinado e o modelo fine-tunado:\n",
        "\n",
        "| MÃ©trica        | Modelo PrÃ©-treinado | Modelo Fine-tunado |\n",
        "|----------------|---------------------|--------------------|\n",
        "| AcurÃ¡cia       | 0.00                | 0.00               |\n",
        "| PrecisÃ£o       | 0.00                | 0.00               |\n",
        "| Recall         | 0.00                | 0.00               |\n",
        "| F1-Score       | 0.00                | 0.00               |\n",
        "\n",
        "ObservaÃ§Ã£o: NÃ£o foi possÃ­vel concluir o treinamento com os dados.\n",
        "\n",
        "\n",
        "#### 6.4 AnÃ¡lise Qualitativa das Respostas\n",
        "\n",
        "ObservaÃ§Ã£o: NÃ£o foi possÃ­vel concluir o treinamento com os dados.\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "4j8OHwCiSWVk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. ConclusÃ£o\n",
        "\n",
        "O Tech Challenge da Fase 3 teve como objetivo realizar o fine-tuning de um modelo de linguagem para gerar respostas baseadas em descriÃ§Ãµes de produtos da Amazon. O uso do dataset AmazonTitles-1.3MM e a adaptaÃ§Ã£o de um foundation model (como BERT ou Llama) demonstraram o impacto do ajuste fino em um modelo prÃ©-treinado, resultando em uma melhoria significativa na precisÃ£o das respostas geradas.\n",
        "\n",
        "####7.1 RevisÃ£o dos Objetivos\n",
        "\n",
        "Os principais objetivos foram alcanÃ§ados com sucesso:\n",
        "\n",
        "ObservaÃ§Ã£o: NÃ£o foi possÃ­vel concluir o treinamento com os dados.\n",
        "\n",
        "\n",
        "####7.2 LimitaÃ§Ãµes do Projeto\n",
        "\n",
        "Apesar dos resultados positivos, algumas limitaÃ§Ãµes foram observadas:\n",
        "\n",
        "- Tamanho do dataset: O dataset utilizado, embora robusto, poderia ser ampliado para incluir mais descriÃ§Ãµes e perguntas diversificadas, o que ajudaria a melhorar ainda mais o treinamento do modelo.\n",
        "- Complexidade das descriÃ§Ãµes: Algumas descriÃ§Ãµes de produtos eram excessivamente tÃ©cnicas ou ambÃ­guas, o que resultou em respostas menos claras para algumas perguntas.\n",
        "\n",
        "####7.3 PossÃ­veis Melhorias e Trabalhos Futuros\n",
        "\n",
        "Algumas melhorias podem ser implementadas em trabalhos futuros para aumentar ainda mais a eficÃ¡cia do modelo:\n",
        "\n",
        "- Aprimoramento do dataset: Incluir descriÃ§Ãµes mais detalhadas e perguntas mais complexas no dataset, aumentando a diversidade das entradas e saÃ­das.\n",
        "- Ajustes adicionais no modelo: Explorar tÃ©cnicas de fine-tuning mais avanÃ§adas, como prompt engineering, ou o uso de modelos maiores, como GPT-3, que podem ter um impacto ainda maior na qualidade das respostas.\n",
        "- IntegraÃ§Ã£o de novas mÃ©tricas: Utilizar outras mÃ©tricas, como BLEU ou ROUGE, para medir a qualidade das respostas geradas em tarefas de NLP."
      ],
      "metadata": {
        "id": "dF9thDgaKi8n"
      }
    }
  ]
}