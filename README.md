# Tech Challenge - FIAP: IA para Devs (Fase 3)

### Grupo 38
- Pedro Vianna Silveira
- Rafael Silva Souza
- Rodrigo de Freitas Ornellas


---

### üîó C√≥digo Github



https://github.com/rafael2mind/tech-challenge-fase-3


### üîó V√≠deo de apresenta√ß√£o
https://youtu.be/

---

### 1. Introdu√ß√£o

#### Contexto e Motiva√ß√£o

Nesta fase do Tech Challenge, o foco est√° em realizar o fine-tuning de um foundation model (como BERT, Llama, Mistral, etc.) utilizando o dataset AmazonTitles-1.3MM. O objetivo √© treinar o modelo para responder perguntas dos usu√°rios com base nas descri√ß√µes de produtos fornecidas no dataset.

O dataset AmazonTitles-1.3MM cont√©m consultas textuais reais de usu√°rios sobre produtos da Amazon, associadas a t√≠tulos de produtos e suas respectivas descri√ß√µes. Com o aumento das intera√ß√µes em plataformas de e-commerce, h√° uma crescente necessidade de sistemas que consigam entender perguntas dos usu√°rios e gerar respostas relevantes, utilizando descri√ß√µes detalhadas dos produtos.

Este projeto prop√µe a constru√ß√£o de um sistema onde, a partir de uma pergunta do usu√°rio sobre um t√≠tulo de produto, o modelo ser√° capaz de gerar uma resposta adequada, utilizando o conhecimento adquirido no processo de fine-tuning com o dataset.


#### Objetivos do Projeto

O principal objetivo deste projeto √© realizar o fine-tuning de um modelo de linguagem com o dataset AmazonTitles-1.3MM para permitir que o modelo:

1. Gere respostas baseadas nas descri√ß√µes dos produtos: A partir de uma pergunta feita pelo usu√°rio sobre o t√≠tulo de um produto, o modelo dever√° gerar uma resposta utilizando as descri√ß√µes presentes no dataset.
2. Melhore a precis√£o e relev√¢ncia das respostas: O fine-tuning do modelo deve permitir uma compreens√£o mais profunda das rela√ß√µes entre o t√≠tulo e a descri√ß√£o de um produto, resultando em respostas mais informativas e √∫teis para o usu√°rio.
3. Documente o processo de ajuste fino: Descrever detalhadamente as etapas de pr√©-processamento de dados, ajuste de hiperpar√¢metros e qualquer modifica√ß√£o feita ao modelo durante o treinamento.


#### Estrutura do Projeto

O projeto ser√° desenvolvido em v√°rias etapas, conforme detalhado a seguir:

1. **Introdu√ß√£o**:
   - Contextualiza√ß√£o do problema.
   - Objetivos do projeto: foco no fine-tuning de um foundation model (como BERT, Llama, Mistral) utilizando o dataset AmazonTitles-1.3MM para gerar respostas baseadas em descri√ß√µes de produtos.

2. **Descri√ß√£o do Problema**:
   - Defini√ß√£o do problema: necessidade de sistemas de NLP capazes de gerar respostas baseadas nas descri√ß√µes de produtos.
   - Import√¢ncia do problema no contexto de plataformas de e-commerce.
   - Abordagem para a resolu√ß√£o do problema.

3. **Fundamenta√ß√£o Te√≥rica**:
   - Modelos de linguagem (foundation models) como BERT, Llama, Mistral.
   - Fine-tuning: t√©cnica de ajuste fino do modelo para tarefas espec√≠ficas.
   - Pr√©-processamento de dados textuais: tokeniza√ß√£o, normaliza√ß√£o, remo√ß√£o de stop words.
   - Gera√ß√£o de respostas em NLP.

4. **Metodologia**:
   - **Prepara√ß√£o dos Dados**: Carregamento do dataset AmazonTitles-1.3MM e pr√©-processamento, incluindo limpeza e cria√ß√£o de prompts.
   - **Sele√ß√£o e Configura√ß√£o do Modelo**: Escolha de um modelo adequado (BERT, Llama, etc.) e tokeniza√ß√£o dos dados.
   - **Execu√ß√£o do Fine-Tuning**: Configura√ß√£o de hiperpar√¢metros, treinamento do modelo e ajustes ao longo do processo.
   - **Avalia√ß√£o e Valida√ß√£o**: Teste do modelo treinado e compara√ß√£o com o modelo pr√©-treinado.

5. **Implementa√ß√£o**:
   - Descri√ß√£o do ambiente de desenvolvimento: ferramentas como Google Colab, bibliotecas como Transformers, Pandas, NumPy, Matplotlib, TensorFlow ou PyTorch.
   - **Carregamento e Prepara√ß√£o do Dataset**: C√≥digo de carregamento, limpeza e tokeniza√ß√£o dos dados.
   - **Fine-tuning do Modelo Escolhido**: Execu√ß√£o do ajuste fino e salvamento do modelo treinado.
   - **Gera√ß√£o de Respostas e Testes**: Fun√ß√£o para gerar respostas a partir de perguntas, avalia√ß√£o de m√©tricas como acur√°cia e F1-score.

6. **Resultados**:
   - An√°lise comparativa do modelo pr√©-treinado e fine-tunado.
   - M√©tricas de avalia√ß√£o e discuss√£o dos resultados obtidos.
   - An√°lise qualitativa das respostas geradas pelo modelo.

7. **Conclus√£o**:
   - Revis√£o dos objetivos e resultados.
   - Limita√ß√µes do projeto e sugest√µes de melhorias para trabalhos futuros.
